\documentclass[a4paper,11pt,twoside]{report}
\usepackage[left=2.5cm,right=2cm,top=2cm,bottom=2cm]{geometry}

% for using customised colours
\usepackage[usenames,dvipsnames]{color}

% for using table
\usepackage[english]{babel}

% for reducing the space between caption and table 
\usepackage{caption}
\captionsetup[table]{skip=0pt}

% for setting the space between caption
\usepackage{lipsum}

% for highlighting a text
\usepackage{soul}


% for adding space between paragraphs
%\usepackage{parskip}
\setlength{\parindent}{1.5em}
\setlength{\parskip}{0.52em}


\usepackage[nodayofweek]{datetime}
\longdate
\setcounter{tocdepth}{4}
\setcounter{secnumdepth}{4}
\setlength{\headheight}{14pt}
 

% for having a balnk page
\usepackage{afterpage}
\newcommand\blankpage{%
\null
\thispagestyle{empty}%
\addtocounter{page}{-1}%
\newpage}

\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{wrapfig}
\usepackage{graphicx}
\usepackage{fancyhdr}
\pagestyle{fancyplain}
\usepackage[T1]{fontenc}
\usepackage[numbib]{tocbibind}

% for jason config
\usepackage{listings}
\usepackage{xcolor}
\usepackage{inconsolata}

\colorlet{punct}{red!60!black}
\definecolor{background}{HTML}{EEEEEE}
\definecolor{delim}{RGB}{20,105,176}
\colorlet{numb}{magenta!60!black}
\bibliographystyle{plain}

\lstdefinelanguage{json}{
    basicstyle=\ttfamily\small,
    breaklines=true,
    frame=tblr,
    framesep=3pt,
    framerule=0pt,
    frameround=tttt, 
    rulecolor=\color{background},
    backgroundcolor=\color{background},
    literate=
     *{0}{{{\color{numb}0}}}{1}
      {1}{{{\color{numb}1}}}{1}
      {2}{{{\color{numb}2}}}{1}
      {3}{{{\color{numb}3}}}{1}
      {4}{{{\color{numb}4}}}{1}
      {5}{{{\color{numb}5}}}{1}
      {6}{{{\color{numb}6}}}{1}
      {7}{{{\color{numb}7}}}{1}
      {8}{{{\color{numb}8}}}{1}
      {9}{{{\color{numb}9}}}{1}
     % {:}{{{\color{punct}{:}}}}{1}
      %{,}{{{\color{punct}{,}}}}{1}
      {\{}{{{\color{delim}{\{}}}}{1}
      {\}}{{{\color{delim}{\}}}}}{1}
      {[}{{{\color{delim}{[}}}}{1}
      {]}{{{\color{delim}{]}}}}{1},
}

% end of jason config

% for terminal formating
\lstset{escapeinside={<@}{@>}}
\lstdefinelanguage{terminal}{
    basicstyle=\ttfamily\small,
    breaklines=true,
    frame=tblr,
    framesep=3pt,
    framerule=0pt,
    frameround=tttt, 
    rulecolor=\color{background},
    backgroundcolor=\color{background},
}

% end of terminal formatting

\usepackage{caption}
\usepackage{subcaption}
\usepackage{ multicol }
\usepackage[title,titletoc,toc]{appendix}
\fancyhf{}

\usepackage{atbegshi}% http://ctan.org/pkg/atbegshi
\AtBeginDocument{\AtBeginShipoutNext{\AtBeginShipoutDiscard}}

\usepackage[title,titletoc,toc]{appendix}
\fancyhf{}
\lhead{\fancyplain{}{Highly Reliable Upgrading of Software Containers}}
%\rhead{\fancyplain{}{\today}}
\cfoot{\fancyplain{}{\thepage}}

\newenvironment{Figure}
  {\par\medskip\indent\minipage{\linewidth}}
  {\endminipage\par\medskip}

\title{Highly Reliable Upgrading of Software Containers\\\Large{--- Literature Survey \& Progress Report ---}}
\author{Samira Rabbanian\\
  samira.rabbanian13@ imperial.ac.uk \\
  \small{Supervisor: Dr.\ Cristian Cadar}\\
  \small{Imperial College London}}

\begin{document}
\maketitle

\begin{titlepage}
    \begin{center}
        \vspace*{2cm}
        
        \large
        {\Large Imperial College London}\\
        \large
         \vspace*{0.2cm}
        {\Large Department of Computing}
        
        \vspace{4.5 cm}
        \large
        {\huge \textbf{Highly Reliable Upgrading of Software Containers}}\\
        \vspace{1.0 cm}
        {\Large by}\\
        {\Large Samira Rabbanian (sr1213)}
        
        \vspace{10cm}
        

  	\large {\Large Submitted in partial fulfilment of the requirements for the MSc Degree in Computing Science of Imperial College London }\\
  	
\vspace*{1 cm}  	
  \large{\Large September 2014}\\ 
           
    \end{center}
\end{titlepage}
\afterpage{\blankpage}
\clearpage

\section*{Abstract}
This is where the abstract will be 
\clearpage


\tableofcontents
\clearpage

\listoffigures
\clearpage

\chapter{Introduction}
\section{Motivation}
Software development is a complex process where errors can easily cause instability, unreliability and incorrect behavior. The most significant problems are; the risks inherent with software upgrade, and the cost of software development and support. 
 
\setlength{\leftskip}{0.5cm}
\setlength{\rightskip}{0.5cm}
\noindent \textbf{Reliable Software Upgrade} - in safety critical industries such as air traffic control or healthcare reliable software is essential for ensuring that lives are not put at risk due to software errors or crashes. In E-commerce reliable software is critical for maximizing the return on investment of software development and deployment. Unreliable software has many damaging impacts such as loss of profit due to unavailability of revenue generating services, damaging reputation of the service provider often with long-term impact, risk of incorrect transactions for example in financial sectors, risk of security vulnerability and costs to fix and monitor errors.

All companies and organizations use software applications to run their business, deliver services or manufacture products. Therefore, software upgrade plays a key role to maintain reliable applications that are free from errors and security vulnerabilities.   Internet facing applications are continuously exposed to an ever increasing set of security threats as listed by the Open Web Application Security Project foundation (OWASP)\footnote{\url{https://www.owasp.org/index.php/Top_10_2013-Top_10}} . These threats include injection attacks, broken authentication and session management, cross-site scripting or cross-site request forgery. To avoid such attacks software must be appropriately patched against vulnerabilities. Once a software security patch has been released, the vulnerability is in the public domain and can therefore be used maliciously by attackers. It is therefore important that software is updated to remove these vulnerabilities.  Furthermore, software is updated to enable new services or functionality to be provided to users. Such updates are often important for companies to ensure they are providing the most reliable, competitive and profitable services to their customers. However, software upgrade itself may cause unreliability by introducing new errors, and security vulnerabilities, as stated by Fred Brooks in The Mythical Man-Month. 

\noindent\textit{ "The fundamental problem with program maintenance is that fixing a defect has a substantial (20-50\%) chance of introducing another. So the whole process is two steps forward and one step back"}  

\hfill \textbf{Fred Brooks, Turing Award Winner (1999) -  The Mythical Man-Month}\bigskip

Recent studies have demonstrated that 14.8\% to 25\% of software upgrades are incorrect and have made impacts on end-users \cite{bugs}. Many different systems and techniques have been proposed to support reliable software upgrade. Currently, these systems are either specific for particular programming languages or are complex, heavyweight and expensive.\medskip 

\noindent \textbf{Reducing Cost of Software Development and Support} - studies have shown that fixing software errors and bugs after delivery is often 100 times more expensive than finding and fixing them during the development process. Moreover, fast feedback is critical in reducing the cost of bugs in all phases (\cite{Boehm_a}, \cite{Boehm_b}). Figure \ref{cost} shows that as the feature development lifecycle progresses the cost of bugs significantly increases. 


Thus, there has been a continuous introduction of new techniques to reduce the feedback cycle.  Initially code review, pair programming and continuous integration were adopted.  More recently these approaches have been further developed into new techniques such as continuous delivery and immutable infrastructures.  However, these more recent techniques are challenging to adopt.  In a typical software development team testing is performed both by developers and software testers on a testing environment that mirrors production.  For continuous delivery and immutable infrastructures to be adopted this testing environment should be updated with the latest software changes on a regular cycle, however, each update takes a long time and prevents any testing on the testing environment.  The frequency of update is therefor in conflict with the availability of the testing environment.  Also the extent to which the infrastructure is immutable is also in conflict as more immutable an infrastructures is the longer the deployment typically takes as more activities are performed during the deployment. 

\begin{figure}[!ht]
  \centering
     \includegraphics[scale=0.25]{cost_of_bugs}
  \caption{Cost of bugs during  feature Development Life Cycle}
  \label{cost}
\end{figure}
% \vspace{-18pt}

\setlength{\leftskip}{0pt}
\setlength{\rightskip}{0pt}
\noindent 
To date, there is no existing system considered robust enough to be used widely for fully automated continuous delivery and reliable software upgrades from development into production.
 
\section{Objectives}
The main objective of this project was to implement a proxy that:

\begin{list}{-}{}
\itemsep0em
\item Support reliable dynamic software update

\item Support seamless rollback to the old version of the application when the upgraded version behaves incorrectly  
\end{list}
 
\section{Contributions}
This report presents a novel, lightweight, robust and reliable proxy that supports dynamic software upgrade with no downtime and automatic rollback in response to application failure. The main features provided are:
\begin{list}{-}{}
\itemsep0em
\item Seamless dynamic software upgrade using four different upgrade mechanisms:
	\begin{itemize}
		\item{Instant upgrade} - immediate upgrade to the latest version of an application 
		\item{Session upgrade} - upgrading only new sessions to the latest version of an application 
		\item{Gradual upgrade} - gradual upgrade of clients to the latest version of an application
		\item{Concurrent upgrade} - routing requests to multiple versions of an application simultaneously and returning the response from the latest version of the application that is behaving correctly 
	\end{itemize}
\item Automatic rollback when an upgraded version does not behave correctly. 
\item Two mechanisms to manage software versions:
	\begin{itemize}
		\item Distinct TCP sockets for each version of an application.  The proxy is configured to communicate with each application version on a separate IP and port combination.
		\item Distinct Docker images for each version of an application.  The proxy manages a Docker container based on each application version using a different image or image tag.  Each application version is therefore isolated in a separate user space sand-boxed process providing resource isolation while sharing a single operating system kernel. 
	\end{itemize}
\item Two mechanisms to configure the proxy:
	\begin{itemize}
		\item File base API in JSON format which is parsed when the proxy loads. All features of the TCP based application version configuration and Docker image based configuration are supported.
		\item A REST API in JSON / HTTP format which can be used to query, add or remove application versions.  All features of the TCP based application version configuration and Docker image based configuration are supported.
	\end{itemize}
\item Extensive support for starting, stopping and updating Docker containers and images, including support for all Docker container and image features.	
\end{list}

\section{Outline of the Report}
\textbf{Chapter 2} - 

\noindent \\
\textbf{Chapter 3} -

\noindent \\
\textbf{Chapter 4} -

\noindent \\
\textbf{Chapter 5} -

\noindent \\
\textbf{Chapter 6} -

\noindent \\
\textbf{Chapter 7} -

\noindent \\
\textbf{Chapter 8} -


\chapter{Related Work}
Software reliability is compromised of the following main activities:

  \begin{list}{-}{}
  \itemsep0em
  \item Error prevention 
  
  \item Fault detection and removal
  
  \item Fault resilience
  \end{list}

\noindent
The Institute of Electrical and Electronics Engineers (IEEE) defines reliability as "the ability of a system or component to perform its required functions under stated conditions for a specified period of time". 
This section of the report describes different approaches and technologies used to achieve and maintain software reliability, specifically to support the activities mentioned above. 

\section{Software High Availability }\label{subsec:rules}
System availability is the percentage of time the system is available to users. A highly available application is fault tolerant and reliable. A reliable system ensures that failure of a single component in the system does not cause failure of the entire application. In a reliable system data updates are not lost and the most recent data is available within acceptable tolerances. 


\subsection*{Software Update} 
Software update typically requires restarting of the system that is to be updated. This can happen in two ways either the system is stopped, the update is applied and the system is restarted. Alternatively the update is applied while the system is still running and then the application is restarted. In the second scenario the system's binary code on persistent storage (\textit{e.g.} disk) is updated while the system is running in memory before it is restarted and the new binary code is loaded into memory \cite{Java}. 

In both cases performing the code update requires the system to be restarted resulting in a period of unavailability. Many applications are performing critical life saving functions and cannot be interrupted, for example, nuclear control systems, air-traffic controllers or hospital life-support software. In addition, other applications have an extremely high downtime cost such as E-commerce, telecommunications and banking systems \cite{fly}. It is therefore extremely important to support seamless upgrade where the system stays fully available during the upgrade. 

Dynamic software update also known as live software update is the process of updating parts of a program without having to interrupt its execution. Dynamic system updates can be performed at either a hardware level or a software level. Hardware based dynamic updating are based on hardware redundancy. Systems such as Tandem Nonstop \cite{Tandem} used in the healthcare and banking industries support dynamic hardware updating and resilience to hardware failure. Detailed techniques and approaches that support dynamic software update are described in section \ref{DSU}. 


\section{Reliable Software Architectures} \label{Architectures}
There are multiple architectures that increase high availability and support dynamic software update. These include application clustering, active-passive architectures, data replication and clustered databases.

\subsection{Application Clustering}
A common practice to increase availability and fault tolerance is using a cluster of multiple application (or component) instances \cite{Clustring}. Most commonly a load balancer is used to distribute the load between nodes in the cluster by pushing requests to each node \cite{balancer}. For example, a load balancer can receive requests for a web application and distribute the requests between different web services so that the load is distributed across all web services. Alternatively, the nodes within the cluster can pull requests as each node becomes available. For instance, a request queue on a Message Oriented Middleware (MOM) or a message broker such as ActiveMQ\footnote{\url{http://activemq.apache.org/}} or RabbitMQ\footnote{ \url{http://www.rabbitmq.com/}} can be used to allow nodes to pull requests (Section \ref{MOM}).

When application requests are balancing across multiple nodes, if a single application (or component) instance fails, other nodes in the cluster will still be available to process requests. This clustering approach therefore improves overall application availability. In addition, a clustering approach provides an increased ability to handle spikes in load. Spikes in load are spread across multiple nodes reducing their impacts on any given server. Moreover, an application that is deployed as a cluster is typically easy to scale horizontally by adding additional nodes because it has been designed to run as a cluster \cite{Clustring}.

One common approach widely used in industry to support dynamic software update is a content switching load balancer (\textit{e.g.} F5\footnote{\url{https://f5.com/}}, Citrix  NetScaler\footnote{\url{http://www.citrix.com/products/netscaler-application-delivery-controller/overview.html}}) in front of an application cluster \cite{balancer}. To perform such an upgrade the cluster is typically split into two halves called A and B. First all load is drained from A by preventing any new requests (\textit{e.g.} business transactions) from being processed. Once A has completed processing all existing requests, it is upgraded and restarted. Now A can start to accept new requests and B is drained and subsequently upgraded. However, this approach is slow and not free from risk as it requires manual interaction with the load balancer to split the cluster and re-route traffic between each step.

\subsection{Active-Passive Architecture}
In addition to clustering another common approach to increase software reliability is to have an active-passive architecture where there are two application instances  (or two application clusters). One of the application instances (or application clusters) is actively receiving requests while the other is passive and it is not processing any load \cite{active_passive}. This arrangement improves reliability because if the active instance starts to behave incorrectly or crashes, all requests can be immediately routed to the passive instance, resulting in the passive instance becoming active. 

A content switching router can be used to automate the routing of requests to the passive instance as soon as it detects the active instance is no longer correctly processing requests. This architecture can also be used to support reliable dynamic software updates. The passive instance can be updated first and requests can slowly start to be routed to the passive instance. During this period if the software update applied to the passive instance fails or causes it to crash, all requests can be immediately routed back to the active instance. However, this approach is wasteful since a complete backup application instance or backup application cluster is required. In addition, this approach is slow and it is not free from risk as it requires manual interaction with the load balancer to re-route traffic.

\subsection{Data Replication}
Data replication can also be used to increase software reliability. Conventional SQL Relation Database Management Systems (RDBMS) typically do not operate in a cluster \cite{Replication}. This is because managing ACID transactions and locking across multiple nodes in a cluster requires commit and rollback to be coordinated across multiple nodes. In addition, consistencies, such as foreign key relationships, must be managed across multiple nodes where the parent and child of the foreign key relationship may be on separate nodes. Although clustered RDBMS do exist, it is expensive, complex and can be error prone. Alternatively, to improve software reliability data can be replicated to a backup database. This works in a similar way to the active-passive architecture where one database is used to process active requests and a second database is only receiving replicated changes and not directly responding to requests. If the active database fails or crashes the passive database can immediately start processing requests and becomes the new active database  \cite{Replication}.

To support dynamic updating of databases, data replication can be used where a backup database receives a replicated copy of the changes made to the primary database. This supports dynamic update in a similar way to the active-passive architecture where software updates can be initially applied to the replicated database; once this is completed, the passive database can replace the active database (and the replication direction is reversed). If the software update fails or causes the database to crash, the non-updated database is still available and can immediately start processing requests again.

\subsection{Clustered Databases}
As the requirements for high availability and high scalability have increased, there has been a shift from using conventional SQL RDBMS to clustered NoSQL databases. In addition, shared database integration is no longer a common technique as it is now widely recognized to break encapsulation and introduce high-coupling. Hence, it is no longer as important for databases to provide strong data integrity. NoSQL databases are designed with clustering and high availability as a priority over strong data integrity and locking \cite{NoSQL}. Therefore, NoSQL databases run in large clusters and replicate data between multiple nodes making them very resilient to failure of one or more nodes. In addition, they are also able to handle rapid increases in load by spreading the load across multiple nodes in the cluster. 

Since NoSQL databases do not provide strong data integrity, it is typically much simpler to dynamically apply updates. For example a document database may store documents in the form of JavaScript Object Notation (JSON)\footnote{\url{http://www.json.org/}}. When the data model is updated by adding or removing fields, no changes to the database are required. Instead applications reading or writing documents are expected to handle different document formats in a flexible way. If such a change was required in a RDBMS, the table structure would need to be modified. The modification is a highly risky activity in a live database and would typically require application downtime and a full database backup.

\section{Reliable Software Techniques}
In addition to architectures that support software reliability, there are also techniques that are commonly used to increase reliability of applying software updates. These include automated deployment, configuration as code and continuous delivery.

\subsection{Automated Deployment}
Automated deployment is used to reduce the cost and the risk associated to installing or updating software. Such an approach is particularly important for cluster or active-passive architectures where the same application must be installed or updated repeatedly. Automated deployment involves using fully scripting application installation or update processes including any operating system (OS) installation, package installation, application installation and configuration \cite{Automated}. There are several tools that are commonly used for automated deployment such as Puppet\footnote{\url{https://puppetlabs.com/}}, Chef\footnote{\url{http://www.getchef.com/chef/}}, Ansible\footnote{\url{http://www.ansible.com/home}} and Salt\footnote{\url{http://www.saltstack.com/enterprise/}}.

\subsection{Configuration As Code}
Configuration as code is a technique used to ensure all environment configuration and settings for an application installation or update are written as code often in the form of an automated deployment script. Such an approach ensures that applications are deployed with the correct environment configuration and that the development team and infrastructure team can easily agree the required configuration \cite{Continuous Delivery}. This approach reduces the risk of deployment by ensuring configuration settings can be tested and reapplied identically every time. In addition, such an approach allows configuration changes to be versioned and changed in-line with the application code or any software updates guaranteeing that the correct configuration for a given update is applied.

\subsection{Continuous Delivery}
Continuous delivery is a software development approach that ensures application updates can be deployed to production at any point throughout the development life cycle. To support continuous delivery a pipeline is typically used to promote application updates automatically through several stages from initial development through to production \cite{Continuous Delivery}. Continuous delivery supports reliable software update by ensuring that each update has been applied to multiple stages prior to reaching production. 

Furthermore, continuous delivery promotes small incremental updates that are deployed on a regular bases reducing the risk from any given update. Continuous delivery also increases software reliability by reducing the cost of applying updates. If an update is extremely easy to deploy, then any defect that has been deployed into production can be more easily fixed by a subsequent deployment. However, continuous delivery from development all the way into production is rare with most companies only managing to promote application updates as far as pre-production. This is because performing automated deployment via continuous delivery into production is considered too risky. This fact reduces many of the benefit that continuous delivery provide.


\subsection{Immutable Infrastructure}

xxxxxxx



\section{Dynamic Software Update Systems} \label{DSU}
Software updates are an important part of maintaining a long-lived system with new software enhancements, fixes and modifications being released on a continuous basis. In the past decades several systems have been developed to support highly reliable dynamic software upgrades. Each of these systems uses different approaches to change the code and the data of a program from an old version to a new version. 

\subsection{Code Update}
Systems such as Ksplice \cite{Ksplice}, OPUS \cite{{opus}} , DynaMOS \cite{Dynamos}, and POLUS \cite{PLOUS}  replace the old code with a small piece of code, called trampoline. Trampoline executes the replaced instruction and then will jump to the function's new version. One of the main weaknesses of using this mechanism is that the trampoline requires a writable code segment, which makes the application vulnerable to code injection attack \cite{Ksplice}. 

Ginseng \cite{Ginseng} and K42 \cite{K42} systems use indirection instead of trampolines. Ginseng uses binary rewriting to direct function calls into calls via function pointers, while K42's OS uses indirection through an object translation table. In the aforementioned systems updates occur by redirecting indirection targets to the new version. However, using this technique can add overhead to normal execution process. 

Dynamic software update systems mentioned above affect code updates at the granularity of individual functions or objects. However, those systems are not capable of updating functions that contain event-handling loops or functions like \textit{main} that rarely end. Hence, systems such as Kitsune  \cite{Kitsune}, UpStare  \cite{UpStare}, Ekiden  \cite{Eiken}, which focus on updating the whole program rather than individual functions have been developed. UpStare uses a stack reconstruction update mechanism. In this mechanism the running application automatically unrolls the call stack when an update occurs, while saving all stack frames. It then modifies the call back by replacing old functions with their new version, and at the same time mapping data structures in the old frames to their new versions. In contrast, Kitsune and Ekiden both use a manual approach by relying on the programmer to migrate control to the correct equivalent point in the new version of the program.


\subsection{Data Update} 
Most dynamic software update systems handle the data update by using object replacement. The system or the developer allocates replacement objects and initialize them using data from the old version. Ginseng uses type-wrapping approach. In this approach the programs are compiled so that \textit{struct}s have an added version field and extra "slop" space to allow for future extensions. Transformation of old objects will be initiated by inserting calls to mediator functions which access updated objects. Ksplice and DynaMOS do not change the old objects but allocate shadow data structures containing only the new fields. Shadow data structures have the advantage of changing fewer functions by an update. When a new field is added to a \textit{struct}, only the code using that field is affected but not all the code that uses the \textit{struct}. 

\section{Dynamic Software Update Safety}
Choosing when to safely apply updates has been one of the main concerns of the prior work on dynamic software updating. Some solutions rely on no updates to active code, \textit{i.e.} no thread is running that code, and no thread's stack refers to it, (\cite{Safety 32}, \cite{Ksplice}, \cite{K42}, \cite{Safety 43} ). This restriction reduces post-update errors but it does not eliminate them, and additionally imposes strong restrictions on the form of an update and how quickly it can be applied. Moreover, some researchers suggest that no updated code should access data generated prior to the update being applied (\cite{Safety 213}, \cite{Safety 214}, \cite{Safety 267}). This technique ensures that updates with type difference do not pose a threat to type safety. The final approach suggested by researchers is using transactions in a distributed or local context to enforce stronger timing constrains (\cite{Safety 173}, \cite{Safety 215}, \cite{Safety 279}). However, it is currently been shown that update timing may not be a main concern and a few programmer-designed update points are typically sufficient to determine safe and timely update states (\cite{Safety 213}, \cite{Kitsune}, \cite{Safety 131}, \cite{Safety 108}). 

\section{Software Update Using Multi-Version Framework} \label{upgrade1} 
The idea of N-version programming, also known as multi-version programming, was originally introduced in 1970s. This method is defined as the independent generation of more than two functionally equivalent programs. Separate developers develop each version of the program all using the same initial specification. These versions will be run concurrently in the application environment. Each version will handle identical inputs and the output of all the versions will be collected and the voting scheme are used to decide which version(s) of the program behave correctly \cite{N-version programming}. N-version programming technique was originally proposed as a method of providing reliable and fault tolerance software. This methodology has inspired many researchers to propose new techniques for development of reliable software applications 

In 1999 Cook \textit{et al.} introduced a multi-version framework called Hercules for the highly reliable upgrading of software components \cite{Cook}. In this framework instead of removing the old version of a component, multiple versions of the same component are kept running in parallel and the behavior of each version is utilized. This approach allows the system integrity to be maintained in the presence of bugs introduced due to the new version of the component. Therefore, Hercules ensures reliability by keeping existing versions of the component running and the old version is only fully removed when the new version has satisfied all its rules. Additionally, Berger and Zorn proposed a replica framework each with a different randomized layout of objects within the heap to provide probabilistic memory safety \cite{Berger}. Furthermore Veeraraghavan et al. suggested running multiple replicas with complementary thread schedules to avoid errors in multi-threaded programs \cite{Veeraraghavan}. 

More recently, Hosek \textit{et al.} proposed a novel framework called Mx, which takes advantage of the idle resources made available by multi-core platforms, and allows applications to survive crash errors introduced by incorrect software updates (\cite{Cadar1}, \cite{Cadar2}). Similar to Hercules, Mx achieves reliability by running the old and new version of an application concurrently. The fundamental difference between the two frameworks is that Hercules requires the programmer to define the functionality of each component version, whilst Mx targets crash bugs and is fully automated. Additionally, in the latter system all versions are live at all times and when Mx detects that one of the versions is not behaving correctly or has crashed, the correctly behaving version is used to handle all software requests. This allows appropriate actions to be taken at a convenient moment; at this point, the incorrectly behaving version can be fixed or restarted. 
\clearpage

\chapter{Technical Background}
This chapter explains and justifies the technologies that will be used in the implementation of the dynamic software update system proposed in chapter \ref{Implementation}.
 
\section{Efficient Cluster Management} 
As described in Section \ref{Architectures} clustering supports dynamic software update and software high availability; however, clustering increases the cost of managing and maintaining the application due to the multiple application instances within the cluster. Virtualization is a technique widely used to reduce the cost of hardware, management and risk associated to clustering.

\subsection{Virtualization} 
Virtualization is the separation of a resource or service from the underlying physical delivery of that resource or service. Virtualization can occur on multiple different infrastructure layers such as network, storage, server hardware, operating systems or applications. Virtual memory, for example, simulates additional memory above the memory that is physically available by using a swap file on hard disk \cite{virtualization}. Filesystems are also virtualized; for example, a Logical Volume Manager (LVM) maps multiple physical disks to logical pools of storage (volume groups). A filesystem can then be created on top of the logical volume within a logical pool (volume group). The filesystem can therefore be spread across multiple physical disks, be re-sized and or moved from one physical disk to another while I/O is happening to the file system\footnote{ \url {http://www.markus-gattol.name/ws/lvm.html}}. 

The main advantage of virtualization is separation between the virtualized infrastructure and the physical infrastructure. This means that applications can continue to execute with no downtime even when physical hardware is replaced, fails or any other hardware maintenance is performed. In addition, physical resources can be pooled and combined then redistributed as required.

\subsubsection*{Hypervisor Virtualization}
Operating system virtualization that is called hypervisor virtualization allows multiple guest operating systems to run on a single host system at the same time \cite{Hypervisors2}. This type of virtualization can be either native based (type 1) or hosted based (type 2) \cite{Hypervisors}. Hosted based hypervisor virtualization uses an application that is installed on an OS such as VMware\footnote{\url{http://www.vmware.com/}} or VirtualBox\footnote{\url {https://www.virtualbox.org/}}. Native hypervisor based virtualization in contrast avoids the overhead of the host OS by running the virtualization layer directly on the host machine (bare-metal). The guest OS shares the hardware of the host computer such that each OS appears to have its own processor, memory and other hardware resources. Since hypervisor has direct access to the hardware resources, it is efficient and enables greater scalability, robustness and performance. In addition, a hypervisor can run the virtualization layer across multiple physical machines \cite{Hypervisors}. This allows new physical machines to be added or maintenance to be performed against existing physical machines transparently without affecting the host operating systems. (Figure \ref{Hypervisor}).\bigskip


%\vspace{-8pt}
\begin{figure}[!ht]
  \centering
     \includegraphics[scale=1]{Hypervisor}
  \caption{Hypervisor Type 1 vs. Type 2 \cite{Hypervisors}}
  \label{Hypervisor}
\end{figure}
%\vspace{-15pt}

\subsubsection*{Container Virtualization} 
Container virtualization is a lightweight operating system virtualization technique that instead of trying to run an entire guest OS, it isolates the guests, but does not virtualize the hardware  \cite{container} (Figure \ref{vm vs container}). Container virtualization is considerably more lightweight than hypervisor virtualization. It has been found to be as much as 40\% less overhead using Docker based container virtualization compared to running full virtual machines on Amazon Elastic Compute Cloud (EC2)\footnote{\url{https://www.appeagle.com/ecommerce-news/ecommerce-is-on-the-rise-in-2013/}}. Each container can be treated like a regular operating system; it can be shut down, booted or rebooted. Resources such as disk space, CPU and memory associated to each container when created can be dynamically increased or decreased while the container is running and applications and users see each container as a separate host. Container virtualization allows installation of several different operating systems on top of a single kernel. Although all the operating systems use the same kernel, they have their own filesystem, processes, memory and devices \cite{container}. \bigskip


%\vspace{-8pt}
\begin{figure}[!ht]
  \centering
     \includegraphics[scale=1]{containervsvm}
  \caption{Containers vs. Traditional Virtual Machines \textsuperscript{\ref{AAA}}}%\footnotemark %\footnotetext{\url{https://www.docker.io/the_whole_story/}} 
  \label{vm vs container}  
\end{figure}
\vspace{-18pt}

\footnotetext{ \label{AAA}\url{https://www.docker.io/the_whole_story/}} 

\noindent
\\\textbf{\textit{Linux Containers}}

\noindent
Container virtualization has been developed independently for different operating systems such as Linux OpenVZ\footnote{\url{http://openvz.org/Main_Page}}, Solaris Containers\footnote{\url{http://www.oracle.com/technetwork/server-storage/solaris/containers-169727.html}}, FreeBSD Jails\footnote{\url{http://www.freebsd.org/cgi/man.cgi?jail}}. A popular example is Linux Containers (LXC)\footnote{\label{LCX} \url{https://linuxcontainers.org/}} that allows a complete copy of the Linux OS to run in a container without the overhead of running a type-2 hypervisor. LXC uses kernel namespaces, AppArmor\footnote{\url{https://wiki.ubuntu.com/AppArmor}}, SELinux\footnote{\url{http://selinuxproject.org/page/Main_Page}}, chroots, and Control groups to provide container virtualization. 

\noindent
Kernel namespaces is used for virtualization of:

\begin{list}{-}{}
  \itemsep0em
  \item Process identifiers
  \item Network interface controllers, firewall rules and routing tables
  \item Hostname
  \item Filesystem layouts 
  \item Interprocess communication
  \end{list}

\noindent 
Control groups is used to provide:

\begin{list}{-}{}
  \itemsep0em
  \item Resource limiting to control use of resources such as memory
  \item Prioritization to control the share of the CPU being used
  \item Accounting to measure how much resources are being used
  \end{list}

\noindent
Chroots, also know as "chroot jails", are used to change the apparent root directory in the filesystem ensuring applications cannot view files and folders outside of the chroot.

AppArmor and SELinux are used to improve security and ensure that applications cannot break out of the LXC \cite{security}.

LXC provides user environments whose resources can be tightly controlled, without the need to virtualize the hardware resources. It also allows running many copies of application configurations on the same system\footnote{\url{https://linuxcontainers.org/}}. This has proven to be a significantly useful feature of these containers for seamless software upgrade (Section \ref{upgrade1}). Furthermore, since the LXC is sharing the kernel with the host system, its processes and filesystem are completely visible from the host; however, this means that the user is limited to the modules and drivers that the container has loaded. \bigskip

%\textsuperscript{\ref{LCX}}

\noindent
\textbf{\textit{Docker}}

\noindent
Docker is an open source application (or framework) that extend and simplifies LXC to provide Linux Containers. Docker allows easy creation of lightweight, portable, self-sufficient containers. Docker extends LXC by providing many features that make it is easier to develop, deploy, automate and share containers\footnote{\label{dockerB} \url{https://www.docker.io/the_whole_story/}}. Docker simplifies containerization supporting techniques such as Continuous Delivery by allowing a Docker container built and tested on a developer's laptop to be run anywhere. Docker containers can run on bare metal servers, virtual machines, OpenStack\footnote{\url{https://www.openstack.org/}} clusters or on a service provider's infrastructure such as Digital Ocean\footnote{\url{https://www.digitalocean.com/}}. 

Advanced Multi-Layered Unification Filesystem (AuFS) is used in Docker as their filesystem. AuFS is a layered filesystem that can transparently overlay one or more existing filesystems (Figure \ref{docker-filesystem}). A Docker AuFS consists of multiple read-only layers with a single read-write layer at the top merged together to form a single filesystem representation. When a file is modified in the container, the read-only version of the file is copied into the read-write layer using a process called copy-on-write \cite{docker2}. The copy-on-write approach means that the read-write layer only contains the files that have been modified by the container. Docker supports behaviors similar to git\footnote {\url{http://git-scm.com/}} where the read-write filesystem layer can be committed and turned into a new permanent read-only layer called an image. A new container can then be created based on this image or committed filesystem layer. A container created from the image will have a union filesystem that unifies a new copy-on-write read-write filesystem layer with the images' read-only filesystem layer and the dependent image filesystem layers beneath it. A Docker image is therefore simply a diff of changes from the previous base layers, effectively keeping the size of image files to minimum. This also means that image creators have a complete audit trail of changes from one version of a container to another. \bigskip

\begin{figure}[!ht]
  \centering
     \includegraphics[scale=0.55]{docker-filesystem}
  \caption{Docker Filesystem\textsuperscript{\ref{filesystem}}} %\footnotemark
  \label{docker-filesystem}
\end{figure}
\footnotetext{ \label{filesystem}\url{https://docs.docker.com/terms/layer/}} 


In addition,  Docker provides a scripting language for creating containers and images based on other images. The script, called a Dockerfile, defines the differences between the new image and the previous base image. Dockerfiles allow the execution of shell commands, the configuration of processes to run when the container is started and control over the public interface of the container including exposed ports and directories. 

Docker also provides a registry of containers called the Docker Index. It allows containers to be publicly shared. The index contains images created by committing a filesystem layer and images created by the Docker Index build system using a Dockerfile \cite{docker2}.
   
With Docker, a new application on a host only needs its binaries or libraries but not a new guest OS. In addition, the same application binaries can be shared between multiple running copies of the application using a shared Docker image. If modifications are made between different versions of the application only the differences need to be maintained separately\footnote{\label{dockerC} \url{https://www.docker.io/the_whole_story/}}. \bigskip

\noindent
\section{Messaging Systems} \label{MOM}
Messaging systems allow two or more applications to exchange information in the form of messaging. Advanced Message Queuing Protocol (AMQP) \cite{AMPQ}, Java Message Service (JMS) \cite{JMS} and Zero Message Queuing (ZeroMQ)\footnote{\label{ZeroMQ_1} \url{http://zeromq.org/}} are the most common messaging standards. 

\subsection{Broker-Based Messaging Systems} 
AMPQ and JMS are popular examples of broker-based messing systems. A message broker (also called Message Oriented Middleware) is a physical component that handles the communications between different applications. Hence, in a broker-based messaging system instead of applications directly communicating with each other, they communicate with the message broker \cite{broker}. The advantage of using this architecture is that the applications do not need to know the location of other applications. They only need to be aware of the network address of the broker. The broker then routes the messages to the correct applications based on the business requirements using the message properties, queue name or routing key \cite{AMPQ}. 

In addition, a broker-based messaging system is more resistant to the application failure. This is because if an application fails, messages that are already in the broker will be retained. However, broker-based messaging systems require excessive amount of network communication. Moreover, since all the messages have to be passed through the broker, the broker can turn out to be a bottleneck in the system. Therefore, the broker can be utilized to 100\% while other components of the system are under-utilized or even idle. Finally, the broker has to be managed and maintained separately to the applications sending and receiving messages. This breaks encapsulation and separation of concerns because the broker contains application specific configuration and logic. Therefore, if the application requirements change, both the broker and the application must be updated in a coordinated way. In addition, one broker often contains logic and queues for several different applications.

\subsection{Zero Broker Messaging Systems} 
In a broker-less messaging system each application directly talks to other applications without any middleware, hence, there are no bottlenecks associated with these systems. The application can manage and maintain its own messaging infrastructure and so encapsulation and separation of concerns are increased.

ZeroMQ is a broker-less, language agnostic, lightweight asynchronous messaging library. Asynchronous I/O model of ZeroMQ asynchronous message-processing required for scalable multi-core applications\footnote{\label{ZeroMQ_2} \url{http://zeromq.org/}}. 

ZeroMQ provide sockets that carry atomic messages across various transports such as Transmission Control Protocol (TCP) or User Datagram Protocol (UDP) and communication styles such as point-to-point or multicast. Unlike conventional sockets that only allow strict one-to-one, many-to-one, or in some cases one-to-many relationships, ZeroMQ sockets can be connected to multiple endpoints while simultaneously accepting incoming connections from multiple endpoints (many-to-many connection). ZeroMQ sockets support connection patterns such as request-reply (sending requests from a client to a web service or cluster of web services and receiving reply from each request sent), publish-subscribe (one-to-many distribution of data from a single publisher to multiple subscribers in a fan out manner), pipeline (distributing data to nodes arranged in a pipeline) and exclusive pair (connect one peer to exactly one other peer for inter-thread communications) patterns that is summarized in \url{http://api.zeromq.org/2-1:zmq-socket}.      

\section{Hypertext Transfer Protocol} \label{HTTP}
The Hypertext Transfer Protocol (HTTP) is a stateless application-level protocol for distributed hypertext and hypermedia information systems supporting the interlinking of text and multimedia.  Hypertext, a term coined by Ted Nelson \cite{hypertext}, is text which is not constrained to be linear and contains links to other texts.  Hypermedia is an extension to hypertext adding support for multimedia, such as images, video and sound.

HTTP is the foundation protocol of the World Wide Web and it is widely used between different systems that need to exchange text and multimedia.  The most common HTTP relationships are client - server and server - server.  The most common client - server relationship is when a web browser (or user agent) browses a web site on a web server.  A server - server relationship is when a web service requires information from another web service, a common example is OAuth\footnote{\label{OAuth} \url{http://oauth.net/}} where a web service can act on behalf of a user by interacting with an OAuth web service provider.  An important feature of HTTP is the typing and negotiation of data representation, allowing systems to be built independently of the data being transferred. This is often referred to REpresentational State Transfer (REST).

\subsection{HTTP Requests} \label{Requests}
An HTTP request has the following format:\bigskip

\begin{lstlisting}[language=terminal, xleftmargin=.3in,xrightmargin=2.5in]
<Request> ::=	<Request-Line>
		<general-headers>
		|<request-headers>
		| <entity-headers> CRLF
		CRLF 
		<opt-message-body>
		
\end{lstlisting} 
\noindent\\
\textit{<Request-Line>} consists of a method, request URI and the protocol version. Method defines the HTTP functions such as GET, POST, PUT, DELETE that is performed on the resources identified by request URI . 

\noindent\\
\textit{<general-headers>} provide general control information and they can be included in both requests and responses. \textit{Transfer-Encoding} is an example of general headers which defines what (if any) type of transformation has been applied to the message body for its safe transfer between the sender and the recipient. For example if \textit{Transfer-Encoding} is defined as "chunked", the data will be sent to the recipient in a series of "chunks". 

\noindent\\
\textit{<request-headers>} allow the client to pass additional information about the request, and about the client itself, to the server. 

\noindent\\
\textit{<entity-headers>} define optional and required meta-information about the request body and if the request has no body, provide information about the resource identified by the request. For example, \textit{Content-Length} header indicates the size of the request body. 

\noindent\\
\textit{CRLF CRLF} indicating a carriage return ('\textbackslash r') followed by a line feed ('\textbackslash n') is used to separate the header section from the body.

\noindent\\
\textit{<opt-message-body>} contains the data transmitted in the body of the request.

\noindent\\
For example the following shows a simple HTTP request:

\begin{lstlisting}[language=bash,xleftmargin=.25in,  xrightmargin=.25in]
GET / HTTP/1.1
User-Agent: curl/7.30.0
Host: 127.0.0.1:1235
Accept: */*
\end{lstlisting} 

\subsection{HTTP Responses}
An HTTP response has the following format:\bigskip

\begin{lstlisting}[language=terminal, xleftmargin=.3in,xrightmargin=2.25in]
<Response> ::=	<Status-Line>
		<general-headers>
		|<response-headers>
		|<entity-headers> CRLF
		CRLF 
		<opt-message-body>
\end{lstlisting} 
\noindent\\
\textit{<Status-Line>} consists of the HTTP version followed by a numeric status code and its associated textual phrase. The status code indicates the action taken on the corresponding request.  The status code has 5 groupings as follows:

\begin{list}{-}{}
\itemsep0em
\item \textbf{1xx Informational} - request received continue processing \textit{e.g.} 101 Switching Protocols
\item \textbf{2xx Success} - request was successfully received, understood, and accepted \textit{e.g.} 202 Accepted
\item \textbf{3xx Redirection} - client actions required to complete the request \textit{e.g.} 301 Moved Permanently
\item \textbf{4xx Client Error} - request contains a syntax error or cannot be fulfilled \textit{e.g.} 400 Bad Request
\item \textbf{5xx Server Error} - server failed to fulfill the request \textit{e.g.} 500 Internal Server Error
\end{list}
\noindent
\textit{<general-headers>} provide general control information and they can be included in both requests and responses. \textit{Transfer-Encoding} is an example of general headers which defines what (if any) type of transformation has been applied to the message body for its safe transfer between the sender and the recipient. For example if \textit{Transfer-Encoding} is defined as "chunked", the data will be sent to the recipient in a series of "chunks". 

\noindent\\
\textit{<response-headers>} allow the server to pass additional information about the response and about the server itself to the client. 

\noindent\\
\textit{<entity-headers>} define optional and required meta-information about the response body and if the response has no body, provide information about the resource returned in the response. For example, \textit{Content-Length} header indicates the size of the response body. 

\noindent\\
\textit{CRLF CRLF} indicating a carriage return ('\textbackslash r') followed by a line feed ('\textbackslash n') is used to separate the header section from the body. 

\noindent\\
\textit{<opt-message-body>} contains the data transmitted in the body of the response.

\noindent\\
For example the following shows a simple HTTP response:
\indent
\begin{lstlisting}[language=bash,xleftmargin=.25in,xrightmargin=.25in]
HTTP/1.1 200 OK
Set-Cookie: dynsoftup=be69fecd-2c53-11e4-9f0f-28cfe9158b63;
Date: Mon, 25 Aug 2014 12:37:35 GMT
Server: Apache/2.2.22 (Debian)
X-Powered-By: PHP/5.4.4-14+deb7u12
X-Pingback: http://192.168.50.40/xmlrpc.php
Vary: Accept-Encoding
Content-Length: 7467
Content-Type: text/html; charset=UTF-8

<!DOCTYPE html> ... </html>
\end{lstlisting} 
\clearpage

\chapter{Design}\label{Design}
To manage the ever-increasing size of E-commerce and web related services large-scale clusters are deployed to virtualized operating systems running on hypervisors. However, hypervisors have a significant overhead when all that is required is a simple way to run clustered instances of applications. Container virtualization is considerably more lightweight than hypervisor virtualization. It has been found to be as much as 40\% less overhead using Docker based container virtualization compared to running full virtual machines on Amazon EC2\footnote{\url{https://www.appeagle.com/ecommerce-news/ecommerce-is-on-the-rise-in-2013/}}.

In addition to the use of virtualization, continuous delivery and automated deployments are critical to reduce the cost of maintaining large clusters of software that require regular updates and feature releases. Although many companies use automated deployment tools, continuous delivery all the way into production is extremely rare due to the significant risk imposed by applying automated updates directly into production.

\section{Dynamic Software Update System}\label{modes} 
To support reliable dynamic software updates a simple lightweight system has been developed suitable for continuous delivery into production. The system runs the updated version concurrently with previous stable versions. The updated version is monitored automatically and if the updated version behaves incorrectly, all requests will be seamlessly routed to the previous stable version with no downtime.

Four mechanisms are supported to enable different reliable update strategies depending on the specific software requirements.

\noindent\\
\underline{Instant Update} 

\noindent
In this mechanism the updated version of software immediately processes all requests. The non-updated version remains running and will be immediately available to process requests if the updated system does not behave correctly. This mechanism is useful when an update must be applied urgently, such as a critical security patch required to stop an in-progress security breach.
   
\begin{figure}[!ht]
  \centering
     \includegraphics[scale=0.30]{instant_upgrade}
  \caption{Instant Upgrade and Failure Rollback}
  \label{instant_upgrade}
\end{figure}
% \vspace{-18pt}

\noindent\\
\underline{Session Update}

\noindent
This update mechanism only switches new sessions to the updated version. A new session is identified by no requests being received from a client within a configured time period. As with Instant Update, the non-updated version however remains running and will be immediately available to process requests if the updated system does not behave correctly. This approach is useful when a low risk update is being made that provides features, which are important to make available to users as rapidly as possible. For example, a low risk update that is providing a new profit making service.

   
\begin{figure}[!ht]
  \centering
     \includegraphics[scale=0.30]{session_upgrade}
  \caption{Session Upgrade}
  \label{session_upgrade}
\end{figure}
% \vspace{-18pt}

\noindent\\
\underline{Gradual Update}

\noindent
This mechanism switches new sessions gradually to the updated version over multiple days or weeks. This approach is particularly useful for risky or complex updates that have a high potential to introduce system instability. This technique is also less risky since the new software version incrementally receives a greater percentage of requests.

   
\begin{figure}[!ht]
  \centering
     \includegraphics[scale=0.30]{gradual_upgrade}
  \caption{Gradual Upgrade}
  \label{gradual_upgrade}
\end{figure}
% \vspace{-18pt}

\noindent\\
\underline{Concurrent Update}

\noindent
In this mechanism the updated and non-updated versions run concurrently and process identical requests.  In this strategy, both the old and the new versions handle all requests and the characteristics of each response is compared to ensure the update is behaving correctly.

   
\begin{figure}[!ht]
  \centering
     \includegraphics[scale=0.30]{concurrent_upgrade}
  \caption{Concurrent Upgrade}
  \label{concurrent_upgrade}
\end{figure}
% \vspace{-18pt}

In all four mechanisms the behavior of the updated software is automatically monitored to confirm the application is behaving correctly. The status code and ability to receive incoming requests is used to verify that the updated application is behaving correctly. Figure \ref{proposed_solution} demonstrates the component interactions within the proposed dynamic software update system. The focus for the dynamic software update system is on HTTP requests and responses.  This focus allows the use of HTTP headers to identify user sessions.  In addition, it allows efficient comparison between large responses without the need to buffer the entire response body.

%\vspace{-8pt}
\begin{figure}[!ht]
  \centering
     \includegraphics[scale=0.31]{proposed_solution}
  \caption{Component interactions within the proposed  dynamic software update system}
  \label{proposed_solution}
\end{figure}
%\vspace{-18pt}


\section{Technology Stack} 
The following technology stack has been chosen for the dynamic software update system:

\begin{list}{-}{}
  \itemsep0em
  \item Go\footnote{\url{http://golang.org/}} programming language for building the proxy \textit{i.e.} the content switching load balancer. Go is chosen because of its simplicity, efficiency, scalability, highly concurrency and garbage collection. Other fast programming languages such as C++ and Java were considered. However, C++ was not chosen since it does not have garbage collection and requires manual memory management. Java was not chosen since it is more heavyweight in comparison to Go, does not give the programmer control over the memory management and is therefore not likely to be as efficient as Go.
    
  \item Docker as a container virtualization mechanism that runs containers for both the target application that is to be updated and the content switching load balancer.
  
  \item ZeroMQ as message frameworks that support highly efficient load balancing and routing of messages without the need for any middleware.

    \end{list}
\clearpage

\chapter{Implementation} \label{Implementation}
To produce an efficient and reliable dynamic software update system several versions of a dynamic software update proxy was implemented using Go programming language as described in this section. 

\section{Message Based Proxy Using ZeroMQ}
The first proxy developed to support dynamic software update was an HTTP reverse proxy based on ZeroMQ messaging system. A custom Dockerfile was written that creates a Docker container running an example web service using Netty\footnote{\url{http://netty.io/}}. The proxy uses different types of ZeroMQ sockets such as STREAM, REQ, REP and it is arranged as shown in Figure \ref{prototype}. Each box is a separate thread, a separate process or a Docker container and performs the following responsibilities:
 
\begin{list}{-}{}
  \itemsep0em
  \item \textbf{upstream} uses STREAM socket for receiving HTTP requests and replying with the HTTP response. Upstream also consists of REQ socket that forwards the requests to the router. 
  
  \item \textbf{router} is responsible for distributing requests across four downstream threads using ROUTER and DEALER sockets. ROUTER socket adds the identity of the sender and receiver to responses and requests respectively. DEALER socket distributes the requests across downstream threads in a round-robin order.
 
  \item \textbf{downstream} is responsible for receiving the requests from the router using REP sockets and sending HTTP requests to the two Docker containers containing the Netty web services and receiving the responses using STREAM socket.
\end{list}

%\vspace{-8pt}
\begin{figure}[!ht]
  \centering
     \includegraphics[scale=0.31]{prototype}
  \caption{Message Based Proxy Using ZeroMQ}
  \label{prototype}
\end{figure}

\subsection{Performance Evaluation}
Detailed analysis of the reverse HTTP proxy showed that when the HTTP requests are chunked (Section \ref{Requests}), ZeroMQ STREAM socket treats each chunk as a separate message and the DEALER socket distributes each chunk of the same request to different recipients. Therefore, it was concluded that ZeroMQ messaging library is not suitable and reliable for load balancing chunked HTTP requests and a simpler approach would be to use raw Go sockets directly. Furthermore, HTTP provides adequate messaging support such as content encoding and caching and wrapping HTTP messages in another message layer adds unnecessary complexity and overhead. Therefore, other messaging systems were not explored for developing a content switching load balancer. 

In conclusion, the ZeroMQ HTTP reverse proxy was not advanced further to support dynamic software update instead an alternative approach using raw sockets was developed. 

\section{Socket Based Proxies}
As it was explained in the previous section using a messaging system was not the correct choice to develop a dynamic software update proxy. This section describes two different approaches using raw Go sockets.   

\subsection{Socket Based Proxy With Content Counting}\label{Content-Counting}
The first version of the socket based proxy was designed as demonstrated in Figure \ref{content_counting_proxy}. The proxy consists of a listener that listens in an  \textit{Accept} loop for new TCP connections. 

When a new connection is received, a TCP connection between the client and the proxy is created over which the HTTP request read from the socket in \textit{Read} loop.  The routing component creates another connection between the proxy and the server.  The HTTP request is then written to the server inside a \textit{Write} loop.

An identical but opposite set of \textit{Read} and \textit{Write} loops are created to return the response from the server back to the client.

%\vspace{-8pt}
\begin{figure}[!ht]
  \centering
     \includegraphics[scale=0.31]{content_counting_proxy}
  \caption{Socket Based Proxy With Content Counting}
  \label{content_counting_proxy}
\end{figure}

\subsubsection*{Content Counting}
The content counting proxy uses the HTTP format to detect the end of each request and response (Section \ref{HTTP}). Detecting the end of requests/responses is used to close connection sockets when the complete message has been transmitted.   For HTTP requests, the method token in the Request-Line is used to detect what type of HTTP function is expected (Section \ref{Requests}). If the method is defined as GET, no message body in the request is expected and the \textit{Read} loop ends after the first read containing all the headers. However, for other HTTP functions such as POST or PUT and for HTTP responses, the Transfer-Encoding and Content-Length headers were used (Section \ref{HTTP}).\medskip 

\noindent
\underline{Content-Length}\medskip

\noindent
When Content-Length header is provided, the size of message body is known upfront.  The proxy then counts the number of bytes in each chunk.  The first chunk can contain both headers and part of the the message body so the CRLF CRLF is used to detect where the message body starts (Section \ref{HTTP}). For each subsequent chunk the content length is counted. When the length of read data is the same as the size defined in Content-Length header, the \textit{Read} loop terminates.\medskip 

\noindent
\underline{Transfer-Encoding: "chunked"}\medskip

\noindent
However, when no Content-Length header is provided, the size of the message body is not known upfront. Instead the Transfer-Encoding header with a value of "chunked" indicates the message body is chunked and a zero chunk will mark the end of the message body.  At the start of each new chunk, the chunk size is defined as a hexadecimal number followed by '\textbackslash r\textbackslash n', therefore, the format for the last chunk is always defined as '0 \textbackslash r\textbackslash n \textbackslash r\textbackslash n'. To detect the end of HTTP messages with chunked Transfer-Encoding header, the content counting proxy screens each chunk and when the last chunk, \textit{i.e.} '0 \textbackslash r\textbackslash n \textbackslash r\textbackslash n', is detected, the  \textit{Read} loop ends. 

\subsubsection*{Performance Evaluation}
To evaluate the performance of the aforementioned proxy an HTTP benchmarking tool called \textit{wrk}\footnote{\label{wrk} \url{https://github.com/wg/wrk}} was used. \textit{wrk} is capable of generating significant load when it runs on a single multi-core CPU by combining a multi-threaded design and scalable event notification systems such as epoll\footnote{\label{epoll} \url{http://man7.org/linux/man-pages/man7/epoll.7.html}} and kqueue\footnote{\label{kqueue} \url{http://www.freebsd.org/cgi/man.cgi?query=kqueue&sektion=2}}.



HTTP Requests were fired to an example Go web service either directly or via the implemented content counting proxy. The processed time for each request was calculated using \textit{wrk}. The following terminal outputs are an example of results obtained by \textit{wrk} when the benchmark was run for 2 minutes, using 400 threads and keeping 400 HTTP connections open. \bigskip  

\noindent
\underline{Direct HTTP Requests To Go Server}
\begin{lstlisting}[language=terminal]
$ ./wrk -t400 -c400 -d120 --latency http://127.0.0.1:1024
Running 2m test @ http://127.0.0.1:1024
  400 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    56.33ms    5.34ms 113.13ms   97.48%
    Req/Sec    17.26      2.09    28.00     94.61%
  Latency Distribution
     50%   55.85ms
     75%   56.36ms
     90%   56.89ms
     99%   97.85ms
  854993 requests in 2.00m, 126.38MB read
Requests/sec:   7123.93
Transfer/sec:      1.05MB
\end{lstlisting}

\noindent\\
\underline{HTTP Requests To Go Server Via Content Counting Proxy} 
\begin{lstlisting}[language=terminal]
$ ./wrk -t400 -c400 -d120 --latency http://127.0.0.1:1234
Running 2m test @ http://127.0.0.1:1234
  400 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency   381.51ms  131.93ms 482.79ms   83.01%
    Req/Sec     0.48      2.34    26.00     95.10%
  Latency Distribution
     50%  472.32ms
     75%  480.15ms
     90%  481.42ms
     99%  482.69ms
  25835 requests in 2.00m, 3.82MB read
  Socket errors: connect 0, read 27144, write 681, timeout 21088
Requests/sec:    215.24
Transfer/sec:     32.58KB
\end{lstlisting}


\noindent \\
The above results show that significant socket errors such as read and write errors occur when the requests are sent to the Go server via proxy. The socket errors consequently reduce the number of requests processed by the server (\textit{e.g.} from 7123.93/second to  215.24/second), the amount of data transferred (\textit{e.g.} from 1.05MB/second to 32.58KB/second) and finally increases the time taken for each request to be processed (average time increased from 56.33ms to 381.51ms). Detailed analysis of the proxy showed that the content counting proxy is not consistently detecting the end of messages, therefore, the read and write sockets do not close appropriately which results in socket errors. 

In conclusion, the significant overhead and socket errors associated with the implemented proxy lead to the conclusion that a proxy with content counting is not suitable for supporting reliable and efficient dynamic software updates. Therefore, another version of the socket based proxy was developed as described in the next section.

\subsection{Socket Based Staged Proxy With End Of File Signal}\label{staged}
The final version of the socket based proxy was implemented using a Stage Based Design (SBD) as demonstrated in Figure \ref{proxy}. The SBD approach was used to improve the code design, simplicity and to support good test coverage. Additionally, the SBD also promoted encapsulation, separation-of-concerns and allowed inversion-of-control and dependency-injection which resulted in the following benefits:

\begin{list}{-}{}
  \itemsep0em
  \item\textbf{Encapsulation And Separation Of Concerns} - resulted in separating logic for each functional area into a single component. This creates a simple and isolated code that focuses on one topic, making it clear and easier to understand. Additionally, encapsulation and separation of concerns simplified testing by allowing each test to be focused on one specific area. For example, multiple tests could be writing focusing on reading from a socket and dealing with different errors and situations that can occur.  This approach increase overall reliability in comparison to the \ref{Content-Counting} proxy. 

  \item\textbf{Inversion-Of-Control And Dependency Injection} - allowed incremental development of the proxy where new components were plugged-in and configured one by one while existing components all worked together. For the HTTP dynamic update proxy shown in Figure \ref{proxy} the \textit{Read} and \textit{Write} stages were first developed. That was followed by development of the  \textit{Complete} and \textit{Route} stages respectively and then the rest of proxy was implemented. Furthermore, This approach also simplified testing of the proxy by allowing the code-under-test to be isolated by mocking all dependencies and permitting the mocking of different error situations that would be impossible to test without mocking dependencies  
\end{list}

\noindent
To prevent the socket errors that occurred in the content counting proxy \ref{Content-Counting}, the staged HTTP dynamic update proxy uses the End-Of-File (EOF) signal to detect the end of messages instead of content counting. Different component and stages of the proxy is shown in Figure \ref{proxy} and their functionality is explained below.\bigskip

\begin{figure}[!ht]
  \centering
     \includegraphics[scale=0.30]{proxy}
  \caption{Staged Socket Based Staged Proxy Design Supporting Dynamic Software Update}
  \label{proxy}
\end{figure}
% \vspace{-18pt}

\subsubsection*{Accept Loop} 
\textit{Accept} loop accepts incoming HTTP connections on a listener and creates a \textit{Forward pipe} for each request.

\subsubsection*{Forward Pipe} 
\textit{Forward pipe} constructs the \textit{ChunkContext Struct} for the received request and creates \textit{Read}, \textit{Route}, \textit{Write} and \textit{Complete} stages of the proxy for forwarding the request to the appropriate server in the cluster. The \textit{ChunkContext Struct} is used to encapsulate the information for managing the transferring chunks of data between the client and servers of the proxy. The \textit{ChunkContext} contains information such as network addresses of the client and the server and the data transfer direction, as follows: \bigskip  

\begin{lstlisting}[language=terminal, xleftmargin= .5in, xrightmargin= 1.75in]
type ChunkContext struct {
	Data                   []byte
	To                     tcp.TCPConnection
	From                   tcp.TCPConnection
	Err                    error
	TotalReadSize          int64
	TotalWriteSize         int64
	PipeComplete           chan int64
	FirstChunk             bool
	RoutingContext         *RoutingContext
	Direction              Direction
}
\end{lstlisting} 

\subsubsection*{Read Stage} 
\textit{Read} stage is responsible for reading input in a loop from the HTTP connection. The \textit{Read} stage in \textit{Forward pipe} reads requests from the client, while the one in \textit{Back pipe} reads responses from the server. The \textit{Read} loop terminates when an error is encountered while reading from a socket. In the staged proxy (Figure \ref{proxy}) when an EOF condition (\textit{i.e.} when no more input is available) occurs, the \textit{Read} loop treats this condition as a low level socket signal and it stops reading from the connection. This approach allows a graceful and efficient way of detecting the end of input. It also prevents the need for parsing requests / responses and the content counting process mentioned in section \ref{Content-Counting}, which is very inefficient and unreliable.  In addition, the socket based proxy handles socket interaction efficiently by only closing sockets when the other end of the connection closes its socket.  This avoids overhead associated with creating new TCP connections such as the TCP 3-way handshake and TCP slow start.
\subsubsection*{Route Stage} \label{route-stage} 
\textit{Route} stage has different functionality in the \textit{Forward Pipe}, for processing requests and \textit{Back pipe}, for processing responses. \bigskip  

\noindent
\underline{Routing in \textit{Forward Pipe}} - When a new request arrives in the \textit{Route} stage, the upgrade transition mode of the cluster with the highest version determines how the request is forwarded. Currently the proxy supports four different upgrade transition modes; INSTANT, SESSION, GRADUAL and CONCURRENT (Section \ref{modes}). The \textit{Route} stage distributes the requests using the modes according to the rules summarized below: 

\begin{list}{-}{}
  \itemsep0em
  \item{\textbf{INSTANT}} - for INSTANT mode requests are always forwarded to the cluster with the highest version.  INSTANT is the default mode so if no upgrade transition is defined for a cluster then it is given INSTANT mode (Section \ref{PUT}).  In INSTANT mode if the latest cluster fails, it will be removed from the set of available clusters resulting in client requests being routed to the previous version.\medskip
  
  \item{\textbf{SESSION}} -  in SESSION mode the proxy generates a  session cookie with a configured expiry time for each request forwarded to that cluster. The session cookie is added as a Set-Cookie header to all HTTP responses. An HTTP client will return the cookie as long as it has not expired.  This ensures that a client will remain on the same cluster version until it has not interacted with the proxy for >= the cookie expiry period.  If a request has a cookie (\textit{i.e.} it has not timed out) the \textit{Route} stage forwards the request to the cluster associated with the uuid in the cookie.  If no cookie is found, requests will be forwarded according to the upgrade transition mode of the cluster with highest version number.  In SESSION mode if the latest cluster fails, it will be removed from the set of available clusters resulting in client requests being routed to the previous version.\medskip
  
   \item{\textbf{GRADUAL}} - an additional transition cookie is used to control GRADUAL mode routing.  The transition cookies is added to each response but as it does not have an expiry time, each client should keep the same cookie. The transition cookie is used to randomly allocate each client a number between 0 and 100. This number is then used to determine which clients should be routed to the latest cluster version.   If the randomly allocated value is <= to a defined threshold then it will be routed to the latest cluster version. As more requests are correctly processed by the latest cluster version, the threshold continually increases.  This results in a gradual increase in the percentage of clients being forwarded to the latest cluster version.  As an example, if the threshold is 15 then 15\% of random clients will use the latest cluster version.  Once a client is assigned a random value, the client will keep that value. Therefore when clients start using the latest cluster, they will remain on that cluster.  However, if the latest cluster fails, it will be removed from the set of available clusters resulting in requests being routed to the previous version. \medskip
   
   \item{\textbf{CONCURRENT}} - for CONCURRENT mode, the \textit{Route} stage forwards requests concurrently to a configurable number of the most updated cluster versions.  If the latest cluster version correctly accepts a new TCP connection and responds with an HTTP status code that is not in the 5xx range, for server errors, then the client will receive a response from the latest cluster.  If the latest cluster does not accept a new TCP connection or responds with an HTTP status code in the 5xx range then the client will receive a response from the previous cluster version.  
   
\end{list}

\noindent
If the latest cluster version is deleted using the REST API or an error occurs while routing the requests to the latest cluster version, the request will be automatically routed to the previous cluster version. If routing to all versions fails, the proxy returns an an empty response and outputs an appropriate error to the terminal indicating that no clusters are available. If the request is successfully routed, a \textit{Back pipe} will be created by \textit{Route} stage for processing responses.   

\noindent\\
\underline{Routing in \textit{Back pipe}} - The \textit{Route} stage processes responses by adding the appropriate cookie headers.  In INSTANT mode a cluster uuid cookie is added with no expiry time.  In SESSION mode a cluster uuid cookie is added with the configured expiry time.  In GRADUAL mode two cookies with no expiry time are added for the cluster uuid and the randomly assigned transition value.  Finally, if the mode is defined as CONCURRENT, the response status code is checked. If the response from the latest version is in the 5xx range, that response will be dropped and the response from the previous version will be returned.  Also in CONCURRENT mode a cluster uuid cookie is added with no expiry time.\bigskip

\subsubsection*{Write Stage} 
\textit{Write} stage writes requests / responses to output stream for the appropriate socket. The writing process stops if any errors such as \textit{ErrShortWrite} are encountered while writing to the socket. The \textit{Write} stage in \textit{Forward pipe} writes data to the server, while the \textit{Write} stage in \textit{Back pipe} writes data to the client. 

\subsubsection*{Complete Stage}
\textit{Complete} stage is responsible for shutting down the writing and reading sides of the TCP connection when the \textit{Read} and \textit{Write} stages terminate. This is done to insure that a TCP connection is reliably closed when the client/server communication is ended. 

\subsubsection*{Back Pipe}
\textit{Back pipe} is responsible for receiving requests from the server and forwarding it to the client. Similar to \textit{Forward pipe}, \textit{Back pipe} constructs the \textit{ChunkContext Struct} for responses and creates \textit{Read}, \textit{Route}, \textit{Write} and \textit{Complete} stages for forwarding the response to the client.

\section{Docker Integration}

Extensive support for managing Docker containers and images, including support for the following features:
	\begin{list}{-}{}
		\itemsep0em	
		\item name of the image to create each container from
		\item the tag for the image, defaulting to `latest`
		\item whether to automatically check for new image versions
		\item the name of the container, defaulting to an auto-generated unique name
		\item the current working directory inside the container's root file system
		\item the container's entrypoint
		\item the environment variables that are set in the running container
		\item the command to be executed when running the container
		\item the container's hostname
		\item mounting volumes from either the host or from another docker container
		\item mounting all the volumes defined for one or more other docker containers, including control over whether the volumes are mounted in read-write or read-only mode
		\item binding ports from within the container to one or more host port and IP combinations
		\item linking the container to another Docker container
		\item setting the user user id and group id of the executing process running inside the container
		\item restricting the container's memory (in bytes)
		\item restricting the container's cpu share using relative weight compared to other containers
		\item adding custom LXC options for the container
		\item giving extended privileges to the container
	\end{list}

\section{Proxy Installation}
The proxy can be installed in two simple steps as follows:
\begin{list}{-}{}
  \itemsep0em
  \item git clone \url {https://github.com/samirabloom/dynamic-software-update} 
  \item make
\end{list}

\noindent
The above steps install the proxy to the PATH by adding it to the \textit{/usr/local/bin} directory. However, this will only work if the PATH environment variable has \textit{/usr/local/bin} in its list of directories. 

\section{Command Line Interface}
The proxy can be run from the command line with the following options:\bigskip

\begin{lstlisting}[language=terminal]
Usage of proxy:
  -configFile="./config.json":  Set the location of the configuration file 
  that should contain configuration to start the proxy, 
  for example:
              {
                  "proxy": {
                      "port": 1235
                  },
                  "configService": {
                      "port": 9090
                  },
                  "cluster": {
                      "servers":[
                          {"hostname": "127.0.0.1", "port": 1034},
                          {"hostname": "127.0.0.1", "port": 1035}
                      ],
                      "version": "1.0"
                  }
              }

  -logLevel="WARN":  Set the log level as "CRITICAL", "ERROR", "WARNING", 
  "NOTICE", "INFO" or "DEBUG"

  -h: Displays this message
\end{lstlisting} 

\noindent\\
For example the following command will run the proxy in the "INFO" log level and uses a file called \textit{config/config\_script.json} for its configuration. 

\begin{lstlisting}[language=json]
proxy -logLevel=INFO -configFile= "config/config_script.json" 
\end{lstlisting}
 
\section{REST API}
The proxy provides a simple REST API (Figure \ref{proxy}) to support dynamically updating the cluster configuration as follows:

\begin{list}{-}{}
  \itemsep0em
  \item\textbf{{PUT /configuration/cluster}} - adds a new cluster configuration
  
  \item\textbf{{GET /configuration/cluster/{clusterId}}} -  gets a single cluster configuration
  
   \item\textbf{{GET /configuration/cluster}} - gets a list of all cluster configurations
   
   \item\textbf{{DELETE /configuration/cluster/{clusterId}}} -  deletes a single cluster configuration
  
\end{list}
\noindent
The REST API supports the following HTTP response codes:

\begin{list}{-}{}
  \itemsep0em
  \item{202 Accepted}  -  a new cluster entity is successfully added or deleted
  
  \item{200 OK} -  cluster(s) entity is successfully returned
  
   \item{404 Not Found} - cluster id is invalid
   
    \item{400 Bad Request } - request syntax is invalid
  
\end{list}

\subsection{PUT /configuration/cluster}\label{PUT}
The PUT request to \textit{/configuration/cluster}  is used to add a new cluster to the proxy. The format of the request body is as follows:\bigskip

\begin{lstlisting}[language=json]
{
    "cluster": {
        "servers": [
            {
                "hostname": "", 
                "port": 0
            }
        ], 
        "version": "", 
        "upgradeTransition": {
            "mode": ""
            "sessionTimeout": 0  
            "percentageTransitionPerRequest": 0
            "percentageTransitionPerRequest": 0  
        }
    }
}
\end{lstlisting}

\noindent\\
The JSON fields are used for the following reasons:

\begin{list}{-}{}
  \itemsep0em
  \item\textbf{{cluster.servers}} - specifies the list of servers in the cluster.
  
  \item\textbf{{cluster.servers[i].ip}} - specifies the IP address or hostname of a server in the cluster.
  
  \item\textbf{{cluster.servers[i].port}} - specifies the port of a server in the cluster.
  
  \item\textbf{{cluster.version}} - specifies the cluster version. 
  
  \item\textbf{{cluster.upgradeTransition}} - allows the configuration of the upgrade transition. If no \textit{upgradeTransition} is specified, the upgrade transition mode defaults to INSTANT.  
  
  \item\textbf{{cluster.upgradeTransition.mode}} - specifies the upgrade transition mode and support the following values: INSTANT, SESSION, GRADUAL and CONCURRENT.
   
  \item\textbf{{cluster.upgradeTransition.sessionTimeout}} - specifies the timeout period assigned to the SESSION transition mode.
  
  \item\textbf{{cluster.upgradeTransition.percentageTransitionPerRequest}} - specifies the transition percentage associated with each request in the GRADUAL transition mode.
\end{list}

\noindent
When the user send a PUT request and successfully adds a new cluster, the proxy responds by returning a cluster id representing the new cluster entity that has been added. Appendix \ref{Appendix  I} demonstrates detailed examples of the PUT requests and responses supported by proxy and the type of values that can be used in each field of the message body.

\subsection{GET - /configuration/cluster/\{clusterId\}} 
GET requests to \textit{/configuration/cluster/\{clusterId\}} gets a single cluster configuration. If no cluster id is specified and the GET request is sent to \textit{/configuration/cluster/}, a list of all the cluster configurations added to the proxy will be returned. The format of the response body for getting a cluster configuration with a specific cluster entity is shown below and detailed examples of GET requests and responses are demonstrated in Appendix \ref{Appendix  I}.\bigskip

\begin{lstlisting}[language=json]
{
    "cluster": {
        "servers": [
            {
                "hostname": "",
                "port": 0
            }
        ],
        "upgradeTransition": {
                "mode": ""
                "sessionTimeout": 0  
                "percentageTransitionPerRequest": 0  
        },
        "uuid": "",
        "version": ""
    }
}

\end{lstlisting}

\subsection{DELETE - /configuration/cluster/\{clusterId\}}
DELETE requests to \textit{/configuration/cluster/\{clusterId\}} deletes a single cluster configuration. No request body and response body is defined for the DELETE request. Appendix \ref{Appendix I} shows an example of a DELETE request and the response received from the proxy.


\section{Dockerising the proxy}
xxxxxx
Talk about how I dockerised the proxy \bigskip
xxxxxx
why didn't use fleet system and coreOS? \bigskip
xxxx

\section{Testing}
As explained by the previous sections, the proxy consists of many components. Therefore, several testing strategies were used to suit the needs of each component (Figure xxxxxxx).\bigskip

XXXXXXXX ADD TEST LEVELS DIAGRAM  XXXXXXXXXXXXXXXXXXX\bigskip

\subsection{Unit Testing}
These tests focus on low level checking of the functionality of each proxy component or function. Inversion-of-control and dependency-injection (Section \ref{staged}) allowed dependencies to be injected into each component or function and therefore supported mocking of all dependencies. The unit tests cover both positive and negative cases resulting in overall of xxxxxxx line coverage and xxxxxxx branch coverage.\bigskip    

XXXXXXXX ADD COVERAGE REPORT XXXXXXXXXXXXXXXXXXX\bigskip

\subsection{Integration Testing}
These tests focus on the integration between different components of the REST API and the proxy. To ensure each component of the REST API integrates correctly, tests were designed to send simultaneous PUT, GET and DELETE requests to the REST server and the responses were asserted. In addition, integration of different stages of the proxy was tested using different scenarios such as testing the behavior of when the proxy is configured for SESSION or CONCURRENT upgrade modes or when a cluster configuration is deleted from the proxy.

\subsection{System Testing}
The aim of these tests is to check that all components of the dynamic software update system including proxy and the REST API work together. System tests were written to cover complete user scenarios. The tests were executed by starting the proxy with an initial cluster configuration. The cluster configuration was then extended using the REST API.  HTTP requests were then sent to the proxy to confirm that the proxy routed the requests to the correct clusters.  Other scenarios also included deleting cluster configuration using the REST API and confirming the routing continued to behave as expected.

\clearpage

\chapter{Evaluation}
This Chapter demonstrates the quantitative and qualitative analysis performed on the dynamic software update proxy presented in Chapter \ref{Implementation}. The quantitative analysis focused on the load and saturation performance of the proxy; the speed that proxy applies an upgrade and rolls back to an older version when an upgraded version does not behave correctly. The qualitative analysis focused on the functional correctness and robustness of the proxy. 

Real applications including Couchbase\footnote{\label{couchbase} \url{http://www.couchbase.com/}}, WordPress\footnote{\label{wordpress} \url{https://wordpress.com/}} and Lighttpd\footnote{\label{lighttpd}\url{http://www.lighttpd.net/}} were used for the evaluations. Couchbase is a widely used high performing clustered NoSQL database and it is designed to handle large numbers of  simultaneous requests. WordPress is a popular and mature content management system for writing blogs and websites based on PHP\footnote{\label{PHP}\url{http://php.net/}} and MySQL\footnote{\label{MySQL}\url{http://www.mysql.com/}}. WordPress was used by more than 23\% of the top 10 million websites as of September 2014\footnote{\label{w3techs}\url{http://w3techs.com/technologies/overview/content_management/all/}}. Therefore, Couchbase and WordPress were ideal applications for evaluating the proxy. Lighttpd is a popular web server used by several high-traffic websites such as Wikipedia and YouTube. Even though Lighttpd is a populate web server, its bug tracking database\footnote{\label{redmine}\url{http://redmine.lighttpd.net/issues/}} shows that it is not crash bug free. hence, in addition to Couchbase and WordPress,  Lighttpd was used to test that the dynamic software update proxy is able to handle updates that cause incorrect behavior or crashes.     

\section{Quantitative Analysis add one sentence for recovery speed test}\label{Quantitative_Analysis}
This section summarizes the load and saturation tests performed on the dynamic software update proxy. The performance of the proxy was also measured under multiple upgrades and different error conditions to evaluate how rapidly the proxy responds to an upgraded application version behaving incorrectly. The aim of these tests were to evaluate the performance and stability of the proxy. Saturation tests focused on stability of the proxy by sending over 400 simultaneous HTTP requests per second to the proxy for 10 hours. The performance tests focused on measuring the overhead added by the proxy to process HTTP requests and responses.



\subsection{xxxx Load Performance and Saturation Tests}\label{load} - A load test will be used to measure the performance as the number of requests increases. This test will demonstrate the delay incurred by the content switching load balancer and the maximum number of requests that the system can handle.





\noindent\\
\hl{\textbf{replace this with proxy's config for running wordpress containers}}
\begin{lstlisting}[language=terminal]
<@\textcolor{blue}{\# run WordPress version 3.9.1 container}@>
docker run --name some-wordpress --link some-mysql:mysql \
           -p 80:80 -d wordpress:3.9.1

<@\textcolor{blue}{\# run WordPress version 3.9.2 container}@>
docker run --name some-wordpress --link some-mysql:mysql 
           -p 80:80 -d wordpress:3.9.2
\end{lstlisting}

\begin{figure}[!ht]
  \centering
     \includegraphics[scale=0.55]{absoloute-wordpress}
  \caption{xxxxxxxxxxxxx}
  \label{absoloute-wordpress}
\end{figure} 

\begin{figure}[!ht]
  \centering
     \includegraphics[scale=0.55]{percentage-wordpress}
  \caption{xxxxxxxxxxxxx}
  \label{percentage-wordpress}
\end{figure} 

\begin{figure}[!ht]
  \centering
     \includegraphics[scale=0.55]{absoloute-couchbase}
  \caption{xxxxxxxxxxxxx}
  \label{absoloute-couchbase}
\end{figure} 

\begin{figure}[!ht]
  \centering
     \includegraphics[scale=0.55]{percentage-couchbase}
  \caption{xxxxxxxxxxxxx}
  \label{percentage-couchbase}
\end{figure} 

\noindent
\underline{Saturation Test} - This test will be performed to measure the performance of the system when it is has been exposed to a moderate number of requests over a prolonged period of time. This test will demonstrate that the system can run for a prolonged period of time without any degradation, such as memory leaks.


\subsection{xxx xxxx Dynamic Upgrade and Recovery Speed}\label{Recovery}
The aim of this evaluation was to measure how rapidly the proxy applies an upgrade and rolls back to an older version of the application when the new version does not behave correctly.   




\noindent
\underline{Update Speed} -Rapid Updates will be performed to measure how quickly the requests will be transferred to the updated version of the software. 

\noindent
\underline{Software Recovery} - Bugs will be introduced to the new version of the software to calculate the speed of switching to the non-updated version. 

\begin{table}
\caption {Proxy Latency for dynamic upgrade and error recovery}
\begin{center}
    \begin{tabular}{ | l | l | l | p{5cm} |}
    \hline
   \textbf{Upgrade Scenarios} & \textbf{Latency (ms)} & \textbf{+\textbackslash }\textbf{- SD (ms)} \\ \hline
    INSATNT Upgrade & 44 &1.36 \\ \hline
    INSTANT Upgrade Failure & 45 & 0.75\\ \hline
    CONCURRENT Upgrade & 44.00 & 0.50\\ \hline
    CONCURRENT Upgrade Failure & 44.00 & 0.49\\
    \hline
    \end{tabular}
\end{center}
\end{table}

\section{Qualitative Analysis}
Qualitative analysis were performed on the dynamic software update proxy (Chapter \ref{Implementation})  using real applications. These evaluations insured that different features of the proxy such as load balancing and dynamic software upgrade functionality behave correctly and the proxy can survive crash bugs in real examples. The following qualitative analysis were performed: 

\begin{list}{-}{}
  \itemsep0em
  \item{Load Balancing Analysis} - To ensure that the proxy acts as a reverse proxy and distributes incoming traffics across a number of servers within a cluster. 

  \item{Real Software Upgrades} - To prove the ability of the proxy to handle different upgrade strategies (\textit{i.e.} INSTANT, SESSION, GRADUAL and CONCURRENT) described in Section \ref{modes} in real applications. 
  
   \item{Handling Incorrect Behavior} - To ensure that the proxy is able to handle updates that cause incorrect behavior and allows systems to survive bugs using real examples. 
\end{list} 

\subsection{Load Balancing Analysis}
The dynamic software update proxy is designed to behave as a load balancer and distribute  HTTP requests across multiple servers. Therefore, to test the load balancing feature of the dynamic software update proxy, HTTP requests were sent to a Couchbase cluster with each node running in a separate Docker container. As shown in (Figure \ref{couchbase_cluster}) the cluster contained three nodes running Couchbase server 2.5.1.  Couchbase servers were chosen for the load balancing evaluation since they form a cluster with shared data. Therefore each server returns an identical response to a given request.

\begin{figure}[!ht]
  \centering
     \includegraphics[scale=0.40]{couchbase_cluster}
  \caption{Couchbase Cluster With Three Servers}
  \label{couchbase_cluster}
\end{figure} 

Each Couchbase node was run within a Docker container inside a virtual machine as shown below. Internally within the virtual machine each Docker container for each Couchbase node used a different internal IP address on the 172.16.0.0 - 172.31.255.255 private range reserved by IANA\footnote{\label{IANA} \url{http://www.iana.org/assignments/iana-ipv4-special-registry/iana-ipv4-special-registry.xhtml}}.  However, as the port has been mapped from each Docker container to the virtual machine, each node can be addressed on a different port of the virtual machine. The following section summarizes the steps executed for load balancing evaluation. \bigskip

\begin{lstlisting}[language=terminal]
<@\textcolor{blue}{\# run first node}@>
docker run --name node_one -i -t -d -p 8091:8091 \
		-e CLUSTER_INIT_USER=Administrator \
		-e CLUSTER_INIT_PASSWORD=password \
		-e SAMPLE_BUCKETS=\"beer-sample\" couchbase

<@\textcolor{blue}{\# run second node}@>
docker run --name node_two -i -t -d -p 9091:8091 \
		--link node_one:couchbase \
		-e CLUSTER_INIT_USER=Administrator \
		-e CLUSTER_INIT_PASSWORD=password couchbase

<@\textcolor{blue}{\# run third node}@>
docker run --name node_three -i -t -d -p 10091:8091 \
		--link node_one:couchbase \
		-e CLUSTER_INIT_USER=Administrator \
		-e CLUSTER_INIT_PASSWORD=password couchbase
\end{lstlisting}


\subsubsection*{Proxy Configuration} 
The proxy was configured to forward HTTP requests to the three nodes in Couchbase cluster (Figure \ref{couchbase_cluster}) using round-robin load balancing. The start-up configuration was echoed back by the proxy as shown in the following terminal output.\bigskip
\begin{lstlisting}[language=terminal]
2014/08/24 19:48:18.309757 config_parse.go:53:   NOTICE - Parsed config file:
{
    "proxy": {
        "port": 1235
    },
    "configService": {
        "port": 9090
    },
    "cluster": {
        "servers":[
            {"ip": "192.168.50.10", "port": 8091},
            {"ip": "192.168.50.10", "port": 9091},
            {"ip": "192.168.50.10", "port": 10091}
        ],
        "version": "2.5.1"
    }
}
as:
Proxy{
	Proxy Address:      0.0.0.0:1235
	ConfigService Port: 9090
	Proxied Servers:    
		version: [2.5.1] 
		[192.168.50.10:8091, 192.168.50.10:9091, 192.168.50.10:10091]
}
\end{lstlisting}

\subsubsection*{HTTP Requests} 
Simultaneous HTTP requests were sent to the running proxy using cURL\footnote{\label{curl_link} \url{http://curl.haxx.se/}}. \smallskip
\begin{lstlisting}[language=terminal]
curl -v \ 
http://Administrator:password@127.0.0.1:1235/pools/default/buckets/beer-sample
\end{lstlisting}


\subsubsection*{Load balancing proxy} 
When the proxy is configured to run with INFO level logging, it prints log entries to the terminal. The following log entries created by the proxy demonstrate that the HTTP requests were distributed between each node in the cluster using round-robin order.\smallskip

%2014/08/26 21:53:44.763483 proxy_context_cluster.go:115:     
%   INFO - Serving response 0 from ip: [127.0.0.1] port: [1036] 
%   version: [9.20] mode: [GRADUAL] 
%   transition counter [100.00] percentage transition per request [50.00]

\begin{lstlisting}[language=terminal]
2014/08/24 19:50:06.560279 proxy_context_cluster.go:104:     
   INFO - Serving response 0 from ip: [192.168.50.10] <@\textcolor{magenta}{port: [8091]}@> 
   version: [2.5] mode: [INSTANT]

2014/08/24 19:52:34.576970 proxy_context_cluster.go:104:     
   INFO - Serving response 1 from ip: [192.168.50.10] <@\textcolor{magenta}{port: [9091]}@> 
   version: [2.5] mode: [INSTANT]

2014/08/24 19:56:00.452493 proxy_context_cluster.go:104:     
   INFO - Serving response 2 from ip: [192.168.50.10] <@\textcolor{magenta}{port: [10091]}@> 
   version: [2.5] mode: [INSTANT]

2014/08/24 19:56:07.619419 proxy_context_cluster.go:104:     
   INFO - Serving response 3 from ip: [192.168.50.10] <@\textcolor{magenta}{port: [8091]}@> 
   version: [2.5] mode: [INSTANT]

2014/08/24 19:56:09.137194 proxy_context_cluster.go:104:     
   INFO - Serving response 4 from ip: [192.168.50.10] <@\textcolor{magenta}{port: [9091]}@> 
   version: [2.5] mode: [INSTANT]

2014/08/24 19:56:19.655983 proxy_context_cluster.go:104:     
   INFO - Serving response 5 from ip: [192.168.50.10] <@\textcolor{magenta}{port: [10091]}@> 
   version: [2.5] mode: [INSTANT]
\end{lstlisting}

\subsubsection*{HTTP Requests \& Responses} 
The following shows an HTTP request and the associated HTTP response received via the proxy from a node in the Couchbase cluster.  Note the time zone used inside the Docker container was set to UTC (Coordinated Universal Time) whereas the time zone on the computer running the proxy was set to BST (British Summer Time). Therefore, terminal log output was 1 hour ahead of the "Date" header in the responses from Couchbase.

\noindent\\
\textit{Request}
\begin{lstlisting}[language=terminal]
GET /pools/default/buckets/beer-sample HTTP/1.1
Authorization: Basic QWRtaW5pc3RyYXRvcjpwYXNzd29yZA==
User-Agent: curl/7.30.0
Host: 127.0.0.1:1235
Accept: */*
<@\\@>
\end{lstlisting}

\noindent\\
\textit{Response}
\begin{lstlisting}[language=terminal]
HTTP/1.1 200 OK
Set-Cookie: dynsoftup=369f06ad-2bbf-11e4-9034-28cfe9158b63;
Server: Couchbase Server
Pragma: no-cache
Date: Sun, 24 Aug 2014 18:50:06 GMT
Content-Type: application/json
Content-Length: 10972
Cache-Control: no-cache

{"name":"beer-sample","bucketType":"membase", ... }
\end{lstlisting}

\subsection{Real Software Upgrades}
The main feature of the implemented proxy described in Chapter \ref{Implementation} is its ability to support dynamic software update for continues delivery into production. The proxy is able to dynamically update an application to a new version. It then runs different versions of an application concurrently and it automatically monitors the behavior of the most updated version. If the updated version behaves incorrectly, the proxy seamlessly removes that version of the application and routes all requests to the previous stable version with no downtime. This section evaluates the aforementioned functionality of the proxy in details using real applications.

Dynamic software upgrade strategies described in Section \ref{modes} were applied on two versions of WordPress (version 3.9.1 and version 3.9.2) application. Each version of WorlPress application was run within a Docker container inside a virtual machine by the proxy as demonstrated in section \ref{load}.

For each upgrade scenarios (i.e. INSTANT, SESSION, GRADUAL and CONCURRENT), the following actions were executed sequentially:

\begin{list}{-}{}
  \itemsep0em
  \item Proxy was initially configured with WordPress application version 3.9.1. 
  \item HTTP requests were sent to the proxy.
  \item Proxy's behavior and the responses received from the proxy  were evaluated. 
  \item An upgrade from WordPress version 3.9.1 to version 3.9.2 was applied by sending PUT HTTP requests to the proxy's configuration service
  \item Proxy's response to the upgrade was evaluated.
  \item HTTP requests were sent to the proxy and the responses were evaluated for the upgrade from WordPress version 3.9.1 to version 3.9.2.
  \item Crash bugs were introduced to the new version of WordPress and proxy's response to the crash was evaluated.
\end{list} 

\subsubsection*{INSTANT Upgrade}
In an INSTANT upgrade the proxy  forwards requests to the most updated version of the application. However, if the most updated version does not behave correctly, the proxy removes that version and forwards requests to the previous version of the application (Section \ref{modes}). This section explains the process executed to evaluate the INSTANT upgrade mode of the proxy.\medskip

\noindent
\textit{Proxy Initial Configuration} - The proxy was configured to forward HTTP requests to a cluster running version 3.9.1 of the WordPress application. The start-up configuration echoed by proxy is shown in the following terminal output.\smallskip

\begin{lstlisting}[language=terminal]
2014/08/25 20:22:24.922144 config_parse.go:53:   NOTICE - Parsed config file:
{
    "proxy": {
        "port": 1235
    },
    "configService": {
        "port": 9090
    },
    "cluster": {
        "servers":[
            {"hostname": "192.168.50.30", "port": 80}
        ],
        "version": "3.9.1"
    }
}
as:
Proxy{
	Proxy Address:      0.0.0.0:1235
	ConfigService Port: 9090
	Proxied Servers:    [version: 3.9.1] [192.168.50.30:80]
}   
\end{lstlisting}

\noindent \\
\textit{HTTP Requests \& Responses} - HTTP requests were sent to the proxy using the following cURL syntax:\smallskip
\begin{lstlisting}[language=terminal] 
curl -v http://127.0.0.1:1235 
\end{lstlisting} 

\noindent\\
When the proxy was run in the INFO level logging, its output to the terminal demonstrated that the HTTP requests were forwarded to the version 3.9.1 of the WordPress. The IP address and the version of the sever that proxy is serving responses from refers to WordPress version 3.9.1 demonstrated in the initial configuration.\smallskip

\begin{lstlisting}[language=terminal] 
2014/08/25 20:22:56.415432 proxy_context_cluster.go:114:     
   INFO - Serving response 0 from ip: [192.168.50.30] port: [80] 
   version: [3.9.1] mode: [INSTANT]
\end{lstlisting} 

\noindent\\
This was further confirmed by the response received from WordPress application via proxy. The "X-Powered-By" and "X-Pingback" headers refer to the PHP version and the IP address of WordPress version 3.9.1, respectively. Note that when a cluster has an INSTANT upgrade mode, the cookie in "Set-Cookie" header of the response associated with that cluster does not have an expiry date. \smallskip  

\begin{lstlisting}[language=terminal] 
HTTP/1.1 200 OK
Set-Cookie: dynsoftup=24e90b08-2c8d-11e4-a649-28cfe9158b63;
Date: Mon, 25 Aug 2014 19:22:57 GMT
Server: Apache/2.4.9 (Debian)
X-Powered-By: PHP/5.5.12-2
X-Pingback: http://192.168.50.30/xmlrpc.php
Vary: Accept-Encoding
Content-Length: 7467
Content-Type: text/html; charset=UTF-8

<!DOCTYPE html> ... </html>
\end{lstlisting} 

\noindent\\
\textit{PUT Request For INSTANT Upgrade} - For an instant upgrade of the WordPress application from version 3.9.1. to version 3.9.2, a cluster containing new version was added to the proxy using the following PUT request: \smallskip 

\begin{lstlisting}[language=terminal] 
curl -v \
http://127.0.0.1:9090/configuration/cluster -X PUT \
--data '{"cluster": {"servers":[{"hostname": "192.168.50.40", "port": 80}],"version": "3.9.2","upgradeTransition": { "mode": "INSTANT" }}}'
\end{lstlisting}

\noindent\\
The proxy acknowledged addition of the new cluster by outputting the following message in the terminal: \smallskip 

\begin{lstlisting}[language=terminal] 
2014/08/25 20:25:16.080385 config_service.go:66:     
   INFO - Received new cluster configuration:
   {
       "cluster": {
           "servers": [
               {
                   "hostname": "192.168.50.40", "port": 80
               }
           ],
           "version": "3.9.2",
           "upgradeTransition": {
               "mode": "INSTANT"
           }
       }
   } 
\end{lstlisting}   

\noindent\\
The PUT request and its associated HTTP response is shown below. The response received from the proxy contained the id of the newly added cluster.\smallskip 

\noindent
\textit{Request}
\begin{lstlisting}[language=terminal]
PUT /configuration/cluster HTTP/1.1
User-Agent: curl/7.30.0
Host: 127.0.0.1:9090
Accept: */*
Content-Length: 126
Content-Type: application/x-www-form-urlencoded
<@\\@>
\end{lstlisting}

\noindent\\
\textit{Response}
\begin{lstlisting}[language=terminal]
HTTP/1.1 202 Accepted
Date: Mon, 25 Aug 2014 19:25:16 GMT
Content-Length: 36
Content-Type: text/plain; charset=utf-8

8aedb902-2c8d-11e4-a649-28cfe9158b63
\end{lstlisting}  

\noindent\\
\textit{Evaluation of the INSTANT Upgrade} - To check that the proxy applies the upgrade immediately and process the requests with the most updated version, HTTP requests were sent to the proxy and responses received from the proxy were analyzed.

The proxy's output to the terminal showed that the proxy is serving responses from version 3.9.2 of the WordPress application. In addition, the "X-Powered-By" and "X-Pingback" headers in the response recieved from proxy after the upgrade refered to the PHP version and the IP address of version 3.9.2 of WordPress application, respectively. \smallskip 

\noindent
\textit{HTTP Request After INSTANT Upgrade}
\begin{lstlisting}[language=terminal]
curl -v http://127.0.0.1:1235
\end{lstlisting}

\noindent\\
\textit{Proxy Log Output After INSTANT Upgrade}
\begin{lstlisting}[language=terminal]
2014/08/25 20:28:20.400747 proxy_context_cluster.go:114:     
   INFO - Serving response 0 from ip: [192.168.50.40] port: [80] 
   version: [3.9.2] mode: [INSTANT]
\end{lstlisting}

\noindent\\
\textit{Response from WordPress Version 3.9.2 }
\begin{lstlisting}[language=terminal]
HTTP/1.1 200 OK
Set-Cookie: dynsoftup=8aedb902-2c8d-11e4-a649-28cfe9158b63;
Date: Mon, 25 Aug 2014 19:28:21 GMT
Server: Apache/2.2.22 (Debian)
X-Powered-By: PHP/5.4.4-14+deb7u12
X-Pingback: http://192.168.50.40/xmlrpc.php
Vary: Accept-Encoding
Content-Length: 7467
Content-Type: text/html; charset=UTF-8

<!DOCTYPE html> ... </html>
\end{lstlisting}

\noindent\\
\textit{Handling Incorrect Behavior} - To assure that the proxy can seamlessly handle updates that cause incorrect behavior, the cluster running version 3.9.2 of WordPress was stopped and the behavior of the proxy was evaluated after sending new HTTP requests to the proxy. The following terminal output demonstrates that the proxy first tried to send requests to the cluster with the highest version. When proxy detected that the cluster is not behaving correctly, in this case it could not communicate with the cluster, the proxy removed the updated version of the cluster from the list of configured clusters and forwarded requests to the previous cluster version. 
%The time shown in the proxy's terminal output demonstrates that the time it takes for the proxy to %switch back to the older version is less than 650 us.

\noindent\\
\textit{Proxy Log Output After WordPress Version 3.9.2 crashed}
\begin{lstlisting}[language=terminal]
2014/08/25 20:32:59.897032 proxy_context_cluster.go:114:     
   INFO - Serving response 1 from ip: [192.168.50.40] port: [80] 
   version: [3.9.2] mode: [INSTANT]
   
2014/08/25 20:32:59.897433 stage_route.go:41:    
   <@\textcolor{red}{ERROR - Error communicating with server - dial tcp 192.168.50.40:80: connection refused}@>

2014/08/25 20:32:59.899682 stage_route.go:42:  
   <@\textcolor{orange}{WARNING - Removing cluster from configuration - version: 3.9.2 [192.168.50.40:80]}@>

2014/08/25 20:32:59.899707 proxy_context_cluster.go:114:     
   INFO - Serving response 1 from ip: [192.168.50.30] port: [80] 
   version: [3.9.1] mode: [INSTANT]
\end{lstlisting}

\noindent\\
\textit{Response After WordPress Version 3.9.2 crashed}
\begin{lstlisting}[language=terminal]
HTTP/1.1 200 OK
Set-Cookie: dynsoftup=24e90b08-2c8d-11e4-a649-28cfe9158b63;
Date: Mon, 25 Aug 2014 19:33:00 GMT
Server: Apache/2.4.9 (Debian)
X-Powered-By: PHP/5.5.12-2
X-Pingback: http://192.168.50.30/xmlrpc.php
Vary: Accept-Encoding
Content-Length: 7467
Content-Type: text/html; charset=UTF-8

<!DOCTYPE html> ... </html>  
\end{lstlisting}
   
\subsubsection*{SESSION Upgrade}
In the SESSION upgrade the proxy generates cookies with a configured expiry time for requests forwarded to that cluster. An HTTP client returns the cookie as long as it is not expired. This insures that the client stays on the same cluster until it has not interacted with the proxy for the duration of the cookie. As with INSTANT update, if the cluster with SESSION upgrade does not behave correctly, it will be removed and requests will be forwarded to the previous version of the application (Section \ref{modes}). This section explains the process executed to evaluate the proxy for SESSION upgrade.\medskip

\noindent
\textit{Proxy Initial Configuration} - The proxy was configured with a cluster running version 3.9.1 of WordPress application. The start-up configuration echoed by proxy is shown in the following terminal output.\smallskip

\begin{lstlisting}[language=terminal]
2014/08/25 21:10:46.064526 config_parse.go:53:   NOTICE - Parsed config file:
{
    "proxy": {
        "port": 1235
    },
    "configService": {
        "port": 9090
    },
    "cluster": {
        "servers":[
            {"hostname": "192.168.50.30", "port": 80}
        ],
        "version": "3.9.1"
    }
}
as:
Proxy{
	Proxy Address:      0.0.0.0:1235
	ConfigService Port: 9090
	Proxied Servers:    version: [3.9.1] [192.168.50.30:80]
}
\end{lstlisting}

\noindent \\
\textit{HTTP Requests \& Responses} - HTTP requests were sent to the WordPress cluster via proxy using the following cURL syntax:\smallskip  

\begin{lstlisting}[language=terminal]
curl -v http://127.0.0.1:1235
\end{lstlisting} 

\noindent\\Since no upgrade transition was defined for the initial configuration, INSTANT mode was assigned to the cluster with version 3.9.1 as shown in the following terminal output echoed by proxy. In addition, The output shows that the proxy is forwarding responses from WordPress with version 3.9.1. \smallskip

\begin{lstlisting}[language=terminal] 
2014/08/25 21:11:18.216192 proxy_context_cluster.go:114:     
   INFO - Serving response 0 from ip: [192.168.50.30] port: [80] 
   version: [3.9.1] mode: [INSTANT]
\end{lstlisting} 

\noindent\\
The "X-Powered-By" and "X-Pingback" headers received by the client also confirmed that the response has been sent by WordPress version 3.9.1.  Note that the Set-Cookie header in the response is set and it has no expiry date. \smallskip 

\begin{lstlisting}[language=terminal] 
HTTP/1.1 200 OK
Set-Cookie: dynsoftup=e6203784-2c93-11e4-88f5-28cfe9158b63;
Date: Mon, 25 Aug 2014 20:11:18 GMT
Server: Apache/2.4.9 (Debian)
X-Powered-By: PHP/5.5.12-2
X-Pingback: http://192.168.50.30/xmlrpc.php
Vary: Accept-Encoding
Content-Length: 7467
Content-Type: text/html; charset=UTF-8

<!DOCTYPE html> ... </html>
\end{lstlisting} 

\noindent\\
\textit{PUT Request For SESSION Upgrade} - A cluster running version 3.9.2 of WordPress application was added to the proxy with SESSION upgrade transition mode and 60 seconds session time out using the following PUT request: \smallskip 

\begin{lstlisting}[language=terminal] 
curl -v http://127.0.0.1:9090/configuration/cluster -X PUT \
--data '{"cluster": {"servers":[{"hostname": "192.168.50.40", "port": 80}],"version": "3.9.2","upgradeTransition": { "mode": "SESSION", "sessionTimeout": 60 }}}'
\end{lstlisting}

\noindent\\
The proxy acknowledged addition of the new cluster by outputting the following message in terminal when it ran in the INFO logging level: \smallskip 

\begin{lstlisting}[language=terminal] 
2014/08/25 21:14:10.079590 config_service.go:66:     
   INFO - Received new cluster configuration:
   {
       "cluster": {
           "servers": [
               {
                   "hostname": "192.168.50.40",
                   "port": 80
               }
           ],
           "version": "3.9.2",
           "upgradeTransition": {
               "mode": "SESSION",
               "sessionTimeout": 60
           }
       }
   }
\end{lstlisting}   

\noindent\\
The PUT request and its associated HTTP response is shown below. The response contains cluster id of the newly added cluster.\smallskip 

\noindent
\textit{Request}
\begin{lstlisting}[language=terminal]
PUT /configuration/cluster HTTP/1.1
User-Agent: curl/7.30.0
Host: 127.0.0.1:9090
Accept: */*
Content-Length: 148
Content-Type: application/x-www-form-urlencoded
<@\\@>
\end{lstlisting}

\noindent\\
\textit{Response}
\begin{lstlisting}[language=terminal]
HTTP/1.1 202 Accepted
Date: Mon, 25 Aug 2014 20:14:10 GMT
Content-Length: 36
Content-Type: text/plain; charset=utf-8

5fba791f-2c94-11e4-88f5-28cfe9158b63s
\end{lstlisting}  

\noindent\\
\textit{HTTP Requests Without Cookie} - To check the proxy behaves correctly with SESSION upgrade, an HTTP request with no cookie was sent to the proxy. The proxy forwarded the HTTP request to the new cluster as shown in the following terminal output: \smallskip   

%2014/08/26 21:53:44.763483 proxy_context_cluster.go:115:     
%   INFO - Serving response 0 from ip: [127.0.0.1] port: [1036] 
%   version: [9.20] mode: [GRADUAL] 
%   transition counter [100.00] percentage transition per request [50.00]

\begin{lstlisting}[language=terminal]
2014/08/25 21:17:22.866773 proxy_context_cluster.go:114:     
   INFO - Serving response 0 from ip: [192.168.50.40] port: [80] 
   version: [3.9.2] mode: [SESSION] 
   session timeout [60] uuid [5fba791f-2c94-11e4-88f5-28cfe9158b63]
\end{lstlisting}

\noindent\\
Analyzing headers in the response (\textit{i.e.} "X-Powered-By" and "X-Pingback") also confirmed that responses were coming from the new cluster running version 3.9.2 of WordPress application. Note that the Set-Cookie header in the response from a cluster with SESSION upgrade mode has an expiry date. \smallskip 

\begin{lstlisting}[language=terminal]
HTTP/1.1 200 OK
Set-Cookie: dynsoftup=5fba791f-2c94-11e4-88f5-28cfe9158b63; Expires=Mon, 25 Aug 2014 21:18:22 BST;
Date: Mon, 25 Aug 2014 20:17:23 GMT
Server: Apache/2.2.22 (Debian)
X-Powered-By: PHP/5.4.4-14+deb7u12
X-Pingback: http://192.168.50.40/xmlrpc.php
Vary: Accept-Encoding
Content-Length: 7467
Content-Type: text/html; charset=UTF-8

<!DOCTYPE html> ... </html>
\end{lstlisting}

\noindent\\
\textit{HTTP Requests With Cookie} - When HTTP requests were sent to the proxy with cookies  associated to an older cluster, the proxy forwarded those requests to the old cluster rather than the new one. This is demonstrated with the following terminal output echoed by proxy and the response received by the client. \medskip 

\noindent
\textit{HTTP request with cookie}
\begin{lstlisting}[language=terminal]
curl -v 'http://127.0.0.1:1235/' \
-H 'Cookie:   dynsoftup=e6203784-2c93-11e4-88f5-28cfe9158b63;'
\end{lstlisting}

\noindent\\
\textit{Proxy Log Output}
\begin{lstlisting}[language=terminal]
2014/08/25 21:24:17.273012 proxy_context_cluster.go:114:     
   INFO - Serving response 1 from ip: [192.168.50.30] port: [80] 
   version: [3.9.1] mode: [INSTANT]
\end{lstlisting}

\noindent\\
\textit{Response}
\begin{lstlisting}[language=terminal]
HTTP/1.1 200 OK
Set-Cookie: dynsoftup=e6203784-2c93-11e4-88f5-28cfe9158b63; Expires=Mon, 25 Aug 2014 21:24:17 BST;
Date: Mon, 25 Aug 2014 20:24:17 GMT
Server: Apache/2.4.9 (Debian)
X-Powered-By: PHP/5.5.12-2
X-Pingback: http://192.168.50.30/xmlrpc.php
Vary: Accept-Encoding
Content-Length: 7467
Content-Type: text/html; charset=UTF-8

<!DOCTYPE html> ... </html>
\end{lstlisting}

\noindent\\
\textit{Handling Incorrect Behavior} - To insure the proxy can handle any errors occurring by the updated cluster, the Docker container running WordPress version 3.9.2 was stopped. HTTP requests subsequently were sent to the proxy and its behavior was screened. The proxy terminal output demonstrated that when the proxy fails to send requests to the most updated cluster, it removes that cluster and forwards the requests to the previous cluster version.  \smallskip

\begin{lstlisting}[language=terminal]
2014/08/25 21:35:10.120521 proxy_context_cluster.go:114:     
   INFO - Serving response 1 from ip: [192.168.50.40] port: [80] 
   version: [3.9.2] mode: [SESSION] session timeout [60] 
   uuid [5fba791f-2c94-11e4-88f5-28cfe9158b63]

2014/08/25 21:35:10.120978 stage_route.go:41:    
    <@\textcolor{red}{ERROR - Error communicating with server - dial tcp 192.168.50.40:80: connection refused}@>
   
2014/08/25 21:35:10.120999 stage_route.go:42:  
    <@\textcolor{orange}{WARNING - Removing cluster from configuration - version: 3.9.2 [192.168.50.40:80]}@>

2014/08/25 21:35:10.121034 proxy_context_cluster.go:114:     
   INFO - Serving response 3 from ip: [192.168.50.30] port: [80] 
   version: [3.9.1] mode: [INSTANT]
\end{lstlisting}
 
\noindent\\
The response received from WordPress application via proxy after the oldest version failed is shown below. Note that the "X-Pingback" header shows the network address of old version of WordPress application. In addition, Since proxy deleted the cluster with SESSION upgrade mode, the uuid cookie in the "Set-Cookie" header does not have an expiry date.\smallskip 

\begin{lstlisting}[language=terminal]
HTTP/1.1 200 OK
Set-Cookie: dynsoftup=e6203784-2c93-11e4-88f5-28cfe9158b63;
Date: Mon, 25 Aug 2014 20:35:10 GMT
Server: Apache/2.4.9 (Debian)
X-Powered-By: PHP/5.5.12-2
X-Pingback: http://192.168.50.30/xmlrpc.php
Vary: Accept-Encoding
Content-Length: 7467
Content-Type: text/html; charset=UTF-8

<!DOCTYPE html> ... </html>
\end{lstlisting}

\subsubsection*{GRADUAL Upgrade}
In the GRADUAL upgrade each client will be allocated a transition cookie. The transition cookie will be used to randomly create each client a number between 0 and 100. The random number will be used to define which client should be upgraded to the new version. If the randomly generated number is less than or equal to a defined threshold then that client will be moved to the latest cluster version (Section \ref{route-stage}). This section summarizes the performance evaluation of the proxy when a GRADUAL upgrade of WordPress from version 3.9.1 to 3.9.2 was applied. \medskip

\noindent
\textit{Proxy Initial Configuration} - The initial configuration of the proxy is shown in the following terminal output echoed by proxy. Note that the proxy was initially configured with version 3.9.1 of WordPress application.\smallskip

\begin{lstlisting}[language=terminal]
2014/08/28 11:05:30.745828 config_parse.go:53:   NOTICE - Parsed config file:
{
    "proxy": {
        "port": 1235
    },
    "configService": {
        "port": 9090
    },
    "cluster": {
        "servers":[
            {"hostname": "192.168.50.30", "port": 80}
        ],
        "version": "3.9.1"
    }
}

as:
Proxy{
	Proxy Address:      0.0.0.0:1235
	ConfigService Port: 9090
	Proxied Servers:    version: 3.9.1 [192.168.50.30:80]
}
\end{lstlisting}

\noindent\\
\textit{HTTP Requests \& Responses} - HTTP requests were sent to WordPress application via proxy using the following cURL syntax:\smallskip

\begin{lstlisting}[language=terminal]
curl -v http://127.0.0.1:1235
\end{lstlisting}

\noindent\\
The following proxy output confirms that the HTTP requests were forwarded to the WordPress application version 3.9.1. Since no upgrade mode was chosen for the cluster, the default mode \textit{i.e.} INSTANT mode was chosen by proxy. \smallskip

\begin{lstlisting}[language=terminal]
2014/08/28 11:06:01.661061 proxy_context_cluster.go:115:     
   INFO - Serving response 0 from ip: [192.168.50.30] port: [80] 
   version: [3.9.1] mode: [INSTANT]
\end{lstlisting}

\noindent\\
"X-Pingback" header of the response received from the proxy further confirmed that proxy is receiving responses from WordPress application version 3.9.1.\smallskip 

\begin{lstlisting}[language=terminal]
HTTP/1.1 200 OK
Set-Cookie: dynsoftup=d7bf97fc-2e9a-11e4-8d7c-600308a8245e;
Date: Thu, 28 Aug 2014 10:06:10 GMT
Server: Apache/2.4.9 (Debian)
X-Powered-By: PHP/5.5.12-2
X-Pingback: http://192.168.50.30/xmlrpc.php
Vary: Accept-Encoding
Content-Length: 7523
Content-Type: text/html; charset=UTF-8
 
<!DOCTYPE html> ... </html>
\end{lstlisting}

\noindent\\
\textit{PUT Request for GRADUAL Upgrade} - The following PUT request was sent to the proxy's configuration service for upgrading WordPress application from version 3.9.1 to version 3.9.2.\smallskip

\begin{lstlisting}[language=terminal]
curl -v \
http://127.0.0.1:9090/configuration/cluster -X PUT \
--data '{"cluster": {"servers":[{"hostname": "192.168.50.40", "port": 80}],"version": "3.9.2","upgradeTransition": { "mode": "GRADUAL", "percentageTransitionPerRequest": 1 }}}'
\end{lstlisting}
 
\noindent \\
The following output echoed by the proxy showed successful addition of the new cluster with GRADUAL upgrade transition mode running WordPress version 3.9.2. \smallskip

\begin{lstlisting}[language=terminal]
2014/08/28 11:11:57.781817 config_service.go:66:     
   INFO - Received new cluster configuration:
   {
       "cluster": {
           "servers": [
               {
                   "hostname": "192.168.50.40", 
                   "port": 80
               }
           ], 
           "version": "3.9.2", 
           "upgradeTransition": {
               "mode": "GRADUAL", 
               "percentageTransitionPerRequest": 1
           }
       }
   }
\end{lstlisting}

\noindent\\ 
A cluster id associated to the new cluster was returned by proxy.\smallskip

\begin{lstlisting}[language=terminal]
PUT /configuration/cluster HTTP/1.1
User-Agent: curl/7.30.0
Host: 127.0.0.1:9090
Accept: */*
Content-Length: 167
Content-Type: application/x-www-form-urlencoded
 
HTTP/1.1 202 Accepted
Date: Thu, 28 Aug 2014 10:11:57 GMT
Content-Length: 36
Content-Type: text/plain; charset=utf-8
 
be709f8f-2e9b-11e4-8d7c-600308a8245e
\end{lstlisting}

\noindent\\
\textit{Evaluation of the GRADUAL Upgrade} - An HTTP request with transition cookie was sent to the proxy after the new cluster was added.\smallskip

\begin{lstlisting}[language=terminal]
curl -v 'http://127.0.0.1:1235/' -H 'Cookie: transition=952c8557-2088-11e4-87e3-600308a8245e;'
\end{lstlisting}

\noindent\\
The proxy used the transition cookie to randomly generate a number which determines when the client will be upgraded to the new version. When multiple HTTP requests were sent to the proxy using the same transition cookie, It was noticed that the upgrade occurred after three requests as it is shown in the following terminal output: \smallskip

\begin{lstlisting}[language=terminal]
2014/08/28 11:15:21.019897 proxy_context_cluster.go:115:     
   INFO - Serving response 0 from ip: [192.168.50.30] port: [80] 
   version: [3.9.1] mode: [INSTANT]

2014/08/28 11:15:22.190838 proxy_context_cluster.go:115:     
   INFO - Serving response 1 from ip: [192.168.50.30] port: [80] 
   version: [3.9.1] mode: [INSTANT]

2014/08/28 11:15:22.988277 proxy_context_cluster.go:115:     
   INFO - Serving response 2 from ip: [192.168.50.30] port: [80] 
   version: [3.9.1] mode: [INSTANT]

2014/08/28 11:15:23.708418 proxy_context_cluster.go:115:     
   INFO - Serving response 0 from ip: [192.168.50.40] port: [80] 
   version: [3.9.2] mode: [GRADUAL] transition counter [4.00] 
   percentage transition per request [1.00]
   
2014/08/28 11:15:24.563001 proxy_context_cluster.go:115:     
   INFO - Serving response 1 from ip: [192.168.50.40] port: [80] 
   version: [3.9.2] mode: [GRADUAL] transition counter [5.00] 
   percentage transition per request [1.00]
\end{lstlisting}

\noindent\\
\textit{Handling Incorrect Behavior} - To insure the proxy forwards requests to the older version of the application if the new version behaved incorrectly, the Docker container running version 3.9.2 of the WordPress application was stopped. The behavior of the proxy was screened when new HTTP requests with transition cookie were sent to the proxy. The following terminal output shows that when the proxy failed connecting to the new version of the application, it removed the cluster from the configuration and forwarded requests to the previous cluster version. \smallskip

\begin{lstlisting}[language=terminal]
2014/08/28 11:20:48.105660 proxy_context_cluster.go:115:     
   INFO - Serving response 2 from ip: [192.168.50.40] port: [80] 
   version: [3.9.2] mode: [GRADUAL] transition counter [8.00] 
   percentage transition per request [1.00]
   
2014/08/28 11:20:48.106281 stage_route.go:28:    
   <@\textcolor{red}{ERROR - Error communicating with server - dial tcp 192.168.50.40:80: connection refused}@>

2014/08/28 11:20:48.106299 stage_route.go:29:  
   <@\textcolor{orange}{WARNING - Removing cluster from configuration - version: 3.9.2 [192.168.50.40:80]}@>

2014/08/28 11:20:48.106319 proxy_context_cluster.go:115:     
   INFO - Serving response 3 from ip: [192.168.50.30] port: [80] 
   version: [3.9.1] mode: [INSTANT]
\end{lstlisting}   

\noindent\\
The following response received after the failure of the cluster running version 3.9.2 showed that version 3.9.1 with IP address "192.168.50.30" is processing the requests.\smallskip

\begin{lstlisting}[language=terminal]
HTTP/1.1 200 OK
Set-Cookie: dynsoftup=ffa87add-2e9b-11e4-ae02-600308a8245e;
Date: Thu, 28 Aug 2014 10:20:56 GMT
Server: Apache/2.4.9 (Debian)
X-Powered-By: PHP/5.5.12-2
X-Pingback: http://192.168.50.30/xmlrpc.php
Vary: Accept-Encoding
Content-Length: 7523
Content-Type: text/html; charset=UTF-8
 
<!DOCTYPE html> ... </html>
\end{lstlisting}     

\subsubsection*{CONCURRENT Upgrade}
In the CONCURRENT mode, the proxy sends HTTP requests to the old and new versions of an application and it monitors the responses arriving from the highest version of the application. If the latest version correctly accepts a new TCP connection and responds with an HTTP status code that is not in the 5xx range, for server errors, then the proxy forwards its response to the client. However, If the latest cluster does not accept a new TCP connection or responds with an HTTP status code in the 5xx range, the proxy drops its response and forwards the response from the older version of the application to the client. To evaluate that the CONCURRENT mode of the proxy works reliably, WordPress version 3.9.1 was upgraded to version 3.9.2. The upgrade process, it is summarized in this section. Proxy log output and the HTTP request and responses are used to demonstrate how the proxy behaves for the concurrent upgrade.

\noindent
\textit{Proxy Initial Configuration} - The following terminal output shows the initial configuration of the proxy. Proxy is configured with version 3.9.1 of WordPress application.\smallskip

\begin{lstlisting}[language=terminal]
2014/08/29 12:39:55.615246 config_parse.go:56:   NOTICE - Parsed config file:
{
    "proxy": {
        "port": 1235
    },
    "configService": {
        "port": 9090
    },
    "cluster": {
        "servers":[
            {"hostname": "192.168.50.30", "port": 80}
        ],
        "version": "3.9.1"
    }
}

as:
Proxy{
    Proxy Address:      0.0.0.0:1235
    ConfigService Port: 9090
    Proxied Servers:    version: 3.9.1 [192.168.50.30:80]
}
\end{lstlisting}  

\noindent
\textit{HTTP Request \& Responses} - HTTP requests were sent to the WordPress application via proxy using cURL.
\begin{lstlisting}[language=terminal]
curl -v http://127.0.0.1:1235
\end{lstlisting}  

\noindent\\
As it is shown in the following terminal output echoed by proxy, WordPress version 3.9.1 was processing the requests. Upgrade transition mode INSTANT was given to the initial configuration since no upgrade mode was specified. \smallskip

\begin{lstlisting}[language=terminal]
2014/08/29 12:40:00.005587 proxy_context_cluster.go:115:     
   INFO - Serving response 0 from ip: [192.168.50.30] port: [80] 
   version: [3.9.1] mode: [INSTANT]
\end{lstlisting}  

\noindent\\
The "X-Pingback" header in the response received from proxy also confirmed that version 3.9.1 of the WordPress application with IP address "192.168.50.30" is processing the requests. \smallskip 

\begin{lstlisting}[language=terminal]
HTTP/1.1 200 OK
Set-Cookie: dynsoftup=32afd70b-2f71-11e4-b59e-600308a8245e;
Date: Fri, 29 Aug 2014 11:40:00 GMT
Server: Apache/2.4.9 (Debian)
X-Powered-By: PHP/5.5.12-2
X-Pingback: http://192.168.50.30/xmlrpc.php
Vary: Accept-Encoding
Content-Length: 7523
Content-Type: text/html; charset=UTF-8
 
<!DOCTYPE html> ... </html>
\end{lstlisting} 

\noindent\\
\textit{PUT Request for CONCURRENT Upgrade} - To upgrade WordPress from version 3.9.1 to version 3.9.2, the following PUT request was sent to the proxy's configuration service: \smallskip

\begin{lstlisting}[language=terminal]
curl -v \
http://127.0.0.1:9090/configuration/cluster -X PUT \
--data '{"cluster": {"servers":[{"hostname": "192.168.50.40", "port": 80}],"version": "3.9.2","upgradeTransition": { "mode": "CONCURRENT"}}}'
\end{lstlisting}  

\noindent\\
The following terminal output showed successful addition of the cluster running version 3.9.2 of WordPress application in CONCURRENT upgrade transition mode:\smallskip

\begin{lstlisting}[language=terminal]
2014/08/29 12:42:55.844840 config_service.go:66:     INFO - Received new cluster configuration:
{
    "cluster": {
        "servers": [
            {
                "hostname": "192.168.50.40", 
                "port": 80
            }
        ], 
        "version": "3.9.2", 
        "upgradeTransition": {
            "mode": "CONCURRENT"
        }
    }
} 
\end{lstlisting} 

\noindent
The response body received from the proxy contained a cluster id associated to the new cluster.\smallskip

\begin{lstlisting}[language=terminal]
HTTP/1.1 202 Accepted
Date: Fri, 29 Aug 2014 11:42:55 GMT
Content-Length: 36
Content-Type: text/plain; charset=utf-8

9e1cb1e4-2f71-11e4-b59e-600308a8245e
\end{lstlisting} 

\noindent\\
\textit{Evaluation of the CONCURRENT Upgrade} - To evaluate the behavior of the proxy after the CONCURRENT upgrade, HTTP requests were sent to the proxy. \smallskip

\begin{lstlisting}[language=terminal]
curl -v http://127.0.0.1:1235
\end{lstlisting}

\noindent\\ 
The proxy's log output showed that the proxy sent requests concurrently to both versions of the WordPress application (\textit{i.e.} version 3.9.1 and 3.9.2). \smallskip 

\begin{lstlisting}[language=terminal]
2014/08/29 12:45:00.892252 proxy_context_cluster.go:115:     
   INFO - Serving response 0 from ip: [192.168.50.40] port: [80] 
   version: [3.9.2] mode: [CONCURRENT]

2014/08/29 12:45:00.892822 proxy_context_cluster.go:115:     
   INFO - Serving response 1 from ip: [192.168.50.30] port: [80] 
   version: [3.9.1] mode: [INSTANT]
\end{lstlisting}

\noindent\\
However, the client only received a response from the most updated version as shown below. Note that the "X-Pingback" header contains the IP address of the WordPress application version 3.9.2. \smallskip

\begin{lstlisting}[language=terminal]
HTTP/1.1 200 OK
Set-Cookie: dynsoftup=9e1cb1e4-2f71-11e4-b59e-600308a8245e;
Date: Fri, 29 Aug 2014 11:45:00 GMT
Server: Apache/2.2.22 (Debian)
X-Powered-By: PHP/5.4.4-14+deb7u12
X-Pingback: http://192.168.50.40/xmlrpc.php
Vary: Accept-Encoding
Content-Length: 7523
Content-Type: text/html; charset=UTF-8

<!DOCTYPE html> ... </html>
\end{lstlisting}

\noindent\\
\textit{Handling Incorrect Behavior} - To insure that the proxy drops responses arriving from the newest version of the application when it is not behaving correctly the following evaluation was performed. Docker container running version 3.9.2 of the WordPress application was stopped and HTTP requests were consequently sent to the proxy using cURL.\smallskip

\begin{lstlisting}[language=terminal]
curl -v http://127.0.0.1:1235
\end{lstlisting}

\noindent\\
The log outputted by proxy showed that proxy concurrently forwards messages to both versions of the WorldPress application. However, since the latest version is not available, the proxy ignores the cluster running the latest version and forwards the respond received from version 3.9.1 to the client as shown below. Note the IP address demonstrated in the "X-Pingback" header of the response refers to version 3.9.1 of the WordPress application.    

\noindent\\
\textit{Proxy Log Output}
\begin{lstlisting}[language=terminal]
2014/08/29 12:47:30.434366 proxy_context_cluster.go:115:     
   INFO - Serving response 1 from ip: [192.168.50.40] port: [80] 
   version: [3.9.2] mode: [CONCURRENT]
   
2014/08/29 12:47:30.434794 proxy_context_cluster.go:115:     
   INFO - Serving response 2 from ip: [192.168.50.30] port: [80] 
   version: [3.9.1] mode: [INSTANT]
\end{lstlisting}


\noindent\\
\textit{Response}
\begin{lstlisting}[language=terminal] 
HTTP/1.1 200 OK
Set-Cookie: dynsoftup=9e1cb1e4-2f71-11e4-b59e-600308a8245e;
Date: Fri, 29 Aug 2014 11:47:30 GMT
Server: Apache/2.4.9 (Debian)
X-Powered-By: PHP/5.5.12-2
X-Pingback: http://192.168.50.30/xmlrpc.php
Vary: Accept-Encoding
Content-Length: 7523
Content-Type: text/html; charset=UTF-8

<!DOCTYPE html> ... </html>
\end{lstlisting}
 


\subsection{xxxxx Handling Incorrect Behavior} 
\hl{ To ensure that the system is able to handle updates that cause incorrect behavior multiple scenarios will be tested. This test will cover situations where a single node, multiple nodes or all nodes in the updated application cluster behave incorrectly. Incorrect behavior will be modeled by either the application crashing or by the application taking too long to respond.



Lighttpd1
is a popular open-source web-server used by
several high-traffic websites such as Wikipedia and YouTube.
Despite its popularity, crash bugs are still a common occurrence
in Lighttpd, as evident from its bug tracking database.2
Below we discuss one such bug, which our approach could
successfully eliminate.
In April 2009, a patch was applied3
to Lighttpd’s code related
to the HTTP ETag functionality. An ETag is a unique string
assigned by a web server to a specific version of a web resource,
which can be used to quickly determine if the resource has
changed. The patch was a one-line change, which discarded
the terminating zero when computing a hash representing the
ETag. More exactly, line 47 in etag.c:
for (h=0, i=0; i < etag->used; ++i) h = (h<<5)
ˆ(h>>27)ˆ(etag->ptr[i]);
was changed to:
for (h=0, i=0; i < etag->used-1; ++i) h = (h<<5)
ˆ(h>>27)ˆ(etag->ptr[i]);
This correctly changed the

This correctly changed the way ETags are computed, but
unfortunately, it broke the support for compression, whose
implementation depended on the previous computation. More
precisely, Lighttpd’s support for HTTP compression uses
caching to avoid re-compressing files which have not changed
since the last access. To determine whether the cached file
is still valid, Lighttpd internally uses ETags. Unfortunately,
the code implementing HTTP compression did not consider
the case when ETags are disabled. In this case, etags->used
is 0, and when the line above is executed, etag->used-1
underflows to a very large value, and the code crashes while
accessing etag->ptr[i]. Interestingly enough, the original
code was still buggy (it always returns zero as the hash value,
and thus it would never re-compress the files), but it was not
vulnerable to a crash.
The segfault was diagnosed and reported in March 20104
and
fixed at the end of April 2010,5 more than one year after it was
introduced. The bottom line is that for about one year, users
affected by this buggy patch essentially had to decide between
(1) incorporating the new features and bug fixes added to the
code, but being vulnerable to this crash bug, and (2) giving up
on these new features and bug fixes and using an old version
of Lighttpd, which is not vulnerable to this bug.
Our approach provides users with a third choice; when a
new version arrives, instead of replacing the old version, we
run both versions in parallel. In our example, consider that we
are using MX to run a version of Lighttpd from March 2009.
When the buggy April 2010 version is released, MX runs it in
parallel with the old one. As the two versions execute:
• As long as the two versions have the same external
behaviour (e.g. they write the same values into the same
files, or send the same data over the network), they are
run side-by-side and MX ensures t}

\clearpage



\chapter{Conclusions \& Future Plans}
xxxxxxxxx\bigskip

xxxxxxxxx\bigskip

xxxxxxxxx\bigskip


\clearpage

\chapter{Appendices}

\section*{Appendix I: Proxy REST API}\label{Appendix I}
The proxy provides a simple REST API to support dynamically updating the cluster configuration as follows:

\begin{list}{-}{}
  \itemsep0em
  \item \textbf{PUT /configuration/cluster} - adds a new cluster configuration  
 \item\textbf{GET /configuration/cluster/{clusterId}} - gets a single cluster configuration
 \item\textbf{GET /configuration/cluster} - gets all cluster configurations
 \item\textbf{DELETE /configuration/cluster/{clusterId}} - deletes a single cluster configuration
\end{list}

\noindent
\textbf{HTTP Response Codes}
\begin{list}{-}{}
  \itemsep0em
\item 202 Accepted - a new cluster entity is successfully added or deleted 
\item 200 OK - cluster(s) entity is successfully returned   
\item 404 Not Found - cluster id is invalid
\item 400 Bad Request - request syntax is  invalid
\end{list}

\noindent
\textbf{PUT - /configuration/cluster}

\noindent
To add a new cluster make a PUT request to \textit{/configuration/cluster}.\bigskip

\noindent
\textit{\textbf{Request Body}}
 
\begin{lstlisting}[language=json]
{
  "cluster": {
    "servers": [
      {
        "hostname": "",
        "port": 0
      }
    ],
    "version": "",
    "upgradeTransition": {
        "mode": ""  <@\textcolor{blue}{// allowed values are "INSTANT", "SESSION", "GRADUAL", "CONCURRENT"}@>
        "sessionTimeout": 0  <@\textcolor{blue}{// only supported for a 'mode' value of "SESSION"}@> 
        "percentageTransitionPerRequest": 0   <@\textcolor{blue}{// only supported for "GRADUAL" mode}@>
      }
    }
}
\end{lstlisting}

\noindent\\
\textbf{cluster.servers}

	\noindent
Type: 'Array'  Default value: '[]'\smallskip

\noindent
This value specifies the list of servers in the cluster\bigskip

\noindent
\textbf{cluster.servers[i].ip}

\noindent
Type: 'String' Default value: 'undefined'\smallskip

\noindent
This value specifies the ip address or hostname of a server in the cluster\bigskip

\noindent
\textbf{cluster.servers[i].port}

\noindent
Type: 'Number' Default value: 'undefined'\smallskip

\noindent
This value specifies the port of a server in the cluster\bigskip

\noindent
\textbf{cluster.version}

\noindent
Type: 'String' Default value: '0.0'\smallskip

\noindent
This value specifies the cluster version. If no version is specified, the version defaults to '0.0'.  The version value is sorted using a string sort so care must be taken when using multi digit version numbers as '13' will be sorted before '3' to resolve this always use '03' for '3'. \bigskip

\noindent
\textbf{cluster.upgradeTransition}

\noindent
Type: 'Object' Default value: ''INSTANT'\smallskip

\noindent
This value allows the configuration of the upgrade transition. If no 'upgradeTransition' is specified, the upgrade transition mode defaults to 'INSTANT'.\bigskip

\noindent
\textbf{cluster.upgradeTransition.mode}

\noindent
Type: 'String' Default value: 'SESSION'\smallskip

\noindent
This value specifies the upgrade transition mode and support the following values: 'INSTANT', 'SESSION', 'GRADUAL', 'CONCURRENT'.\bigskip

\noindent
\textbf{cluster.upgradeTransition.sessionTimeout}

\noindent
Type: 'Number' Default value: 'undefined'\smallskip

\noindent
This value specifies the timeout period assigned to the 'SESSION' transition mode. \bigskip

\noindent
\textbf{cluster.upgradeTransition.percentageTransitionPerRequest}

\noindent
Type: 'Number' Default value: 'undefined'\smallskip

\noindent
This value specifies the transition percentage associated with each request in the `GRADUAL` transition mode. \bigskip

\noindent
\textbf{Response Body}

\noindent
A cluster id is returned representing the new cluster entity that has been added. \bigskip

\noindent
\textbf{Example}\bigskip

\noindent
\textbf{Request}

\noindent
For example the following JSON would set up a new cluster with two 'servers' and 'SESSION' upgrade transition:\bigskip

\begin{lstlisting}[language=json]
{
  "cluster": {
    "servers": [
      {
        "hostname": "127.0.0.1", 
        "port": 1036
      },  
      {
        "hostname": "127.0.0.1", 
        "port": 1038
      }
    ], 
    "version": "1.1", 
    "upgradeTransition": {
      "mode": "SESSION", 
      "sessionTimeout": 60
    }
  }
}
\end{lstlisting}

\noindent \\
To send this request with 'cURL' use the following syntax:\bigskip

\begin{lstlisting}[language=terminal]
curl \
http://127.0.0.1:9090/configuration/cluster -X PUT \
--data '{"cluster": {"servers":[{"hostname": "127.0.0.1", "port": 1036},{"hostname": "127.0.0.1", "port": 1038}],"version": "1.1","upgradeTransition": { "mode": "SESSION", "sessionTimeout": 60 }}}'
\end{lstlisting}

\noindent \\
\textbf{Response}

\begin{lstlisting}[language=terminal]
HTTP/1.1 202 Accepted
Date: Sat, 16 Aug 2014 19:54:21 GMT
Content-Length: 36
Content-Type: text/plain; charset=utf-8
 
1dcbb083-257f-11e4-bcbc-600308a8245e
\end{lstlisting}

\noindent \\
\textit{\textbf{GET - /configuration/cluster/{clusterId}}}\bigskip

\noindent 
To get a single cluster configuration make a GET request to \textit{/configuration/cluster/{clusterId}}.\bigskip 

\noindent 
\textbf{Response Body}

\begin{lstlisting}[language=json]
{
  "cluster": {
    "servers": [
      {
        "hostname": "",
        "port": 0
      }
    ],
    "upgradeTransition": {
      "mode": ""
      "sessionTimeout": 0  <@\textcolor{blue}{// only returned when 'mode' is "SESSION" }@>
      "percentageTransitionPerRequest": 0  <@\textcolor{blue}{// only returned when 'mode' is "GRADUAL"}@>
    },
    "uuid": "",
    "version": ""
  }
} 
\end{lstlisting}

\noindent \\
\textbf{Example}

\noindent \\
\textbf{Request}

\noindent 
For example the following 'curl' request would get the cluster configuration with cluster id '1dcbb083-257f-11e4-bcbc-600308a8245e':\bigskip

\begin{lstlisting}[language=terminal]
curl \
http://127.0.0.1:9090/configuration/cluster/\
1dcbb083-257f-11e4-bcbc-600308a8245e -X GET
\end{lstlisting}

\noindent \\
\textbf{Response}

\begin{lstlisting}[language=json]
{
  "cluster": {
    "servers": [
      {
        "hostname": "127.0.0.1",
        "port": 1036
      },
      {
        "hostname": "127.0.0.1",
        "port": 1038
      }
     ],
    "upgradeTransition": {
        "mode": "SESSION",
        "sessionTimeout": 60
    },
    "uuid": "<@{\textcolor{numb}{016ca2cd-2585-11e4-ab5c-600308a8245e}@>",
    "version": "1.1"
  }
}
  
\end{lstlisting}

\noindent \\
For example the response when using curl is as follows:\bigskip

\begin{lstlisting}[language=terminal]
HTTP/1.1 200 OK
Date: Sat, 16 Aug 2014 20:37:42 GMT
Content-Length: 206
Content-Type: text/plain; charset=utf-8

{
    "cluster": {
        "servers": [
            {
                "hostname": "127.0.0.1", 
                "port": 1036
            }, 
            {
                "hostname": "127.0.0.1", 
                "port": 1038
            }
        ], 
        "upgradeTransition": {
            "mode": "SESSION", 
            "sessionTimeout": 60
        }, 
        "uuid": "016ca2cd-2585-11e4-ab5c-600308a8245e", 
        "version": "1.1"
    }
}
\end{lstlisting}

\noindent \\
\textit{\textbf{GET - /configuration/cluster}}\\
\noindent 
To get all the cluster configurations make a GET request with no cluster id \textit{/configuration/cluster/}.

\noindent \\
\textbf{Response Body}

\begin{lstlisting}[language=json]
[
  {
    "cluster": {
      "servers": [
        {
          "hostname": "",
          "port": 0
        }
       ],
      "upgradeTransition": {
        "mode": ""
        "sessionTimeout": 0  // only returned when 'mode' is "SESSION" 
        "percentageTransitionPerRequest": 0  // only returned when 'mode' is "GRADUAL"
      },
      "uuid": "",
      "version": ""
    }
  },
  {
    "cluster": {
      "servers": [
        {
          "hostname": "",
          "port": 0
        },
        {
          "hostname": "",
          "port": 0
        }
       ],
      "upgradeTransition": {
        "mode": "CONCURRENT"
      },
      "uuid": "",
      "version": ""
    }
  }
]
\end{lstlisting}

\noindent \\
\textbf{Example}

\noindent \\
\textbf{Request}

\noindent 
For example the following 'curl' request would get a list of all cluster configurations\bigskip

\begin{lstlisting}[language=terminal]
curl http://127.0.0.1:9090/configuration/cluster/ -X GET
'''
##### Response

\begin{lstlisting}[language=json]
[
  {
    "cluster": {
      "servers": [
        {
          "hostname": "127.0.0.1", 
          "port": 1036
        }, 
        {
          "hostname": "127.0.0.1", 
          "port": 1038
        }
      ], 
      "upgradeTransition": {
        "mode": "SESSION", 
        "sessionTimeout": 60
      }, 
      "uuid": "1f6a0854-2608-11e4-ab79-600308a8245e", 
      "version": "1.1"
    }
  }, 
  {
    "cluster": {
      "servers": [
        {
          "hostname": "127.0.0.1", 
          "port": 1037
        }, 
        {
          "hostname": "127.0.0.1", 
          "port": 1039
        }
      ], 
      "upgradeTransition": {
        "mode": "CONCURRENT"
      }, 
      "uuid": "01386f1f-2608-11e4-ab79-600308a8245e", 
      "version": "1.1"
    }
  }, 
  {
    "cluster": {
      "servers": [
        {
          "hostname": "127.0.0.1", 
          "port": 1034
        }, 
        {
          "hostname": "127.0.0.1", 
          "port": 1035
        }
      ], 
      "upgradeTransition": {
        "mode": "INSTANT"
      }, 
      "uuid": "ffde36ce-2607-11e4-ab79-600308a8245e", 
      "version": "1"
    }
  }
]
\end{lstlisting}

\noindent \\
For example the response when using curl is as follows:\bigskip

\begin{lstlisting}[language=terminal]
HTTP/1.1 200 OK
Date: Sun, 17 Aug 2014 12:28:55 GMT
Content-Length: 583
Content-Type: text/plain; charset=utf-8
 
[
    {
        "cluster": {
            "servers": [
                {
                    "hostname": "127.0.0.1", 
                    "port": 1036
                }, 
                {
                    "hostname": "127.0.0.1", 
                    "port": 1038
                }
            ], 
            "upgradeTransition": {
                "mode": "SESSION", 
                "sessionTimeout": 60
            }, 
            "uuid": "1f6a0854-2608-11e4-ab79-600308a8245e", 
            "version": "1.1"
        }
    }, 
    {
        "cluster": {
            "servers": [
                {
                    "hostname": "127.0.0.1", 
                    "port": 1037
                }, 
                {
                    "hostname": "127.0.0.1", 
                    "port": 1039
                }
            ], 
            "upgradeTransition": {
                "mode": "CONCURRENT"
            }, 
            "uuid": "01386f1f-2608-11e4-ab79-600308a8245e", 
            "version": "1.1"
        }
    }, 
    {
        "cluster": {
            "servers": [
                {
                    "hostname": "127.0.0.1", 
                    "port": 1034
                }, 
                {
                    "hostname": "127.0.0.1", 
                    "port": 1035
                }
            ], 
            "upgradeTransition": {
                "mode": "INSTANT"
            }, 
            "uuid": "ffde36ce-2607-11e4-ab79-600308a8245e", 
            "version": "1"
        }
    }
]
\end{lstlisting}

\noindent \\
\textbf{DELETE - /configuration/cluster/{clusterId}}

\noindent 
To delete a single cluster configuration make a DELETE request to \textit{/configuration/cluster/{clusterId}}.\bigskip

\noindent 
\textbf{Example}\bigskip

\noindent 
\textbf{Request}

\noindent 
For example the following cURL request would delete the cluster configuration with id '1dcbb083-257f-11e4-bcbc-600308a8245e':\bigskip

\begin{lstlisting}[language=terminal]
curl \
http://127.0.0.1:9090/configuration/cluster/\
1dcbb083-257f-11e4-bcbc-600308a8245e -X DELETE
\end{lstlisting}

\noindent \\
\textbf{Response}

\noindent 
For example the response when using curl is as follows:\bigskip

\begin{lstlisting}[language=terminal]
HTTP/1.1 202 Accepted
Date: Sat, 16 Aug 2014 21:28:38 GMT
Content-Length: 0
Content-Type: text/plain; charset=utf-8
\end{lstlisting}


\clearpage

\begin{thebibliography}{1}
\bibitem {Java} Alessandro Orso, Anup Rao, and Mary J. Harrold. {\em A Technique for Dynamic Updating of Java Software.}, CSM Proceedings of the International Conference on Software, 2002.
 
  \bibitem {fly} M. E. Segal and O. Frieder. \textit{On-the-fly program modification: Systems for dynamic updating.} IEEE Software, 1993.

   \bibitem {Tandem}  A. Thakur. {\em Analysis of failures in the Tandem NonStop-UX Operating System.}, Proceedings., Sixth International Symposium on Software Reliability Engineering, 1995. 
   
    \bibitem {Clustring} Ohba, Mitsuru. {\em Software reliability analysis models.}, IBM Journal of Research and Development, 1984.
    
    \bibitem {active_passive} {\em Using passive replicates in Delta-4 to provide dependable distributed computing.}, Fault-Tolerant Computing, 1989. 
    
     \bibitem {Replication} Swarup Acharya , Swarup Acharya , Stanley B. Zdonik , Stanley B. Zdonik. {\em An Efficient Scheme for Dynamic Data Replication.}, Tech Report, 1993. 
   
	 \bibitem {NoSQL} Jaroslav Pokorny. {\em NoSQL databases: a step to database scalability in web environment.}, International Journal of Web Information Systems, 2013. 
	 
	\bibitem {Automated} Akhil Sahai, Calton Pu, Gueyoung Jung, Qinyi Wu, Wenchang Yan, Galen S. Swint. {\em Towards Automated Deployment of Built-to-Order Systems.}, Ambient Networks, 2005  
	  
  \bibitem {Continuous Delivery}  Jez Humble, David Farley. {\em Continuous Delivery: Reliable Software Releases Through Build, Test, and Deployment Automation.}, Addison-Wesley Professional Publisher, 2010.     
   
   \bibitem {balancer}  George Apostolopoulos, David Aubespin, Vinod Peris, Prashant Pradhan, Debanjan Saha {\em Design, implementation and performance of a content-based switch.}, Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies, 2000.
   
  \bibitem {Ksplice} J. Arnold and M. F. Kaashoek. {\em Ksplice: automatic rebootless kernel updates.}, EuroSys, 2009.
  
   \bibitem {opus} G. Altekar, I. Bagrak, P. Burstein, and A. Schultz. {\em OPUS: Online patches and updates for security.}, USENIX Security, 2005.


  \bibitem{Dynamos} K. Makris and K. D. Ryu. {\em Dynamic and Adaptive Updates of Non-Quiescent Subsystems in Commodity Operating System Kernels.}, EuroSys, 2007. 
  
  \bibitem {PLOUS} H. Chen, J. Yu, C. Hang, B. Zang, and P.-C. Yew. {\em Dynamic software updating using a relaxed consistency model.}, IEEE Transactions on Software Engineering, 2011.

  \bibitem {Ginseng} I. Neamtiu, M. Hicks, G. Stoyle, and M. Oriol. {\em Practical dynamic software updating for C.}, PLDI, 2006.
  
  \bibitem {K42} A. Baumann, J. Appavoo, D. D. Silva, J. Kerr, O. Krieger, and R. W. Wisniewski. {\em Providing dynamic update in an operating system.} USENIX ATC, 2005. 

  \bibitem {UpStare} K. Makris and R. Bazzi. {\em Immediate Multi-Threaded Dynamic Software Updates Using Stack Reconstruction.}, USENIX ATC, 2009.

 \bibitem {Eiken} C. M. Hayden, E. K. Smith, M. Hicks, and J. S. Foster. {\em State transfer for clear and efficient runtime upgrades.}, HotSWUp, 2011.
 
  \bibitem {Kitsune} C. M. Hayden, E. K. Smith, M. Denchev, M. Hicks, and J. S. Foster, {\em "Kitsune: Efficient, general-purpose dynamic software updating for C"}, OOPSLA, 2012.
  
  \bibitem {Safety 32} Gautam Altekar, Ilya Bagrak, Paul Burstein, and Andrew Schultz. {\em OPUS: Online patches and updates for security.}, USENIX Security Symp, 2005. 

  \bibitem {Safety 43} Andrew Baumann, Jonathan Appavoo, Robert W. Wisniewski, Dilma Da Silva, Orran Krieger, and Gernot Heiser. {\em Reboots are for hardware: Chal- lenges and solutions to updating an operating system on the fly.}, USENIX Annual Tech. Conf., 2007. 
  
  \bibitem {Safety 214} Iulian Neamtiu, Michael Hicks, Gareth Stoyle, and Manuel Oriol. {\em Practical dynamic software updating for C.}, ACM SIGPLAN Conf. on Programming Language Design and Implementation, 2006.

  \bibitem {Safety 213} Iulian Neamtiu and Michael Hicks. {\em Safe and timely updates to multi-threaded programs.} ACM SIGPLAN Conf. on Programming Language Design and Implementation,  2009.

  \bibitem {Safety 267} Gareth Stoyle, Michael Hicks, Gavin Bierman, Peter Sewell, and Iulian Neamtiu. Mutatis mutandis: {\em Safe and predictable dynamic software updating.}, ACM Trans. Program. Lang. Syst., 29(4), 2007.
  
  \bibitem {Safety 131} ] C. M Hayden, E. K Smith, M. Hicks, and J. S Foster. {\em State transfer for clear and efficient runtime updates.}, In Proc. of the Third Int'l Workshop on Hot Topics in Software Upgrades, pages 179 - 184, 2011.

  \bibitem {Safety 108} Cristiano Giuffrida, Anton Kuijsten, and Andrew S. Tanenbaum. {\em Enhanced operating system security through efficient and fine-grained address space randomization.}, USENIX Security Symp., 2012.

  \bibitem {Safety 215} Iulian Neamtiu, Michael Hicks, Jeffrey S. Foster, and Polyvios Pratikakis. {\em Contextual effects for version-consistent dynamic software updating and safe concurrent programming.}, ACM SIGPLAN Conf. on Programming Language Design and Implementation, 2008. 

  \bibitem {Safety 173} Jeff Kramer and Jeff Magee. {\em The evolving philosophers problem: Dynamic change management.}, IEEE Trans. Softw. Eng., 1990. 

 \bibitem {Safety 279} Yves Vandewoude, Peter Ebraert, Yolande Berbers, and Theo D'Hondt. {\em Tranquility: A low disruptive alternative to quiescence for ensuring safe dynamic updates.}, IEEE Trans. Softw. Eng., 2007.

 \bibitem {Cook} Jonathan E. Cook and	Jeffrey A. Dage. {\em "Highly reliable upgrading of components"}, ICSE Conf. on Proceedings of the 21st international conference on Software engineering, 1999.

 \bibitem {Berger} Emery D Berger and Benjamin Zorn. {\em DieHard: probabilistic memory safety for unsafe languages.}, ACM SIGPLAN Conf. on Programming Language Design and Implementation, 2006.
 
 \bibitem {Veeraraghavan} Kaushik Veeraraghavan, Peter M. Chen, Jason Flinn, and Satish Narayanasamy. {\em detecting and surviving data races using complementary schedules}, SOSP, 2011. 
 
 \bibitem {Cadar1} Petr Hosek and Cristian Cadar. {\em Safe software updates via multi-version execution.}, Int'l Conf. on Software Eng., pages 612-621, 2013.
 
 \bibitem {Cadar2} Cristian Cadar and Petr Hosek. {\em Multi-version software updates.}, In Proc. of the Fourth Int'l Workshop on Hot Topics in Software Upgrades, 2012.

 	\bibitem{N-version programming} Liming. Chen and Algirdas Avizienis. {\em  "N-version programming: A fault-tolerance approach to reliability of software operation"}, in FTCS, 1978. 
   
	\bibitem{virtualization} N.M. Mosharaf Kabir Chowdhurya,1, Raouf Boutaba b. {\em A survey of network virtualization}, Computer Networks, 2010.
   
	\bibitem {Hypervisors2} Thomas C. Bressoud, Fred B. Schneider. {\em Hypervisor-based fault tolerance.}, ACM 	Transactions on Computer System, 1996.
	   
  	\bibitem{Hypervisors} Bhanu P Tholeti. {\em Hypervisors, virtualization, and the cloud: Learn about hypervisors, system virtualization, and how it works in a cloud environment}, IBM, 2011. 

	 \bibitem {container} Steven J Vaughan-Nichols. {\em New Approach to Virtualization Is a Lightweight.}, Computer, 2006.  
	 
	  \bibitem {security} Jyotiprakash Sahoo. {\em Virtualization: A Survey on Concepts, Taxonomy and Associated Security Issues.}, Computer and Network Technology, 2010.
  
   \bibitem {docker2} Dirk Merkel. {\em Docker: Lightweight Linux Containers for Consistent Development and Deployment.}, Linux Journal, 2014.
	
	\bibitem{AMPQ} Steve Vinoski. {\em Advanced Message Queuing Protocol}, IEEE Internet Computing, 2006. 

    \bibitem{JMS} Mark Hapner, Rich Burridge, Rahul Sharma, Joseph Fialli, Kate Stout. {\em Java Message Service}, In Oracle America, Inc., 2012.

\bibitem{broker} Aneesh Raj, P. Sreenivasa Kumar, {\em "Branch Sequencing Based XML Message Broker Architecture,"}, IEEE 23rd International Conference on Data Engineering, 2007.  

\bibitem{hypertext} A File Structure for the Complex, the Changing, and the Indeterminate. 20th National Conference, New York, Association for Computing Machinery, 1965

\bibitem{bugs}Yin Z, Yuan D, Zhou Y, Pasupathy S, and Bairavasundaram L, \textit{"How
do fixes become bugs?"}, ESEC/FSE, 2011.

\bibitem{Boehm_a}Boehm, B. W, \textit{Improving software productivity}, IEEE Computer, 1987a.

\bibitem{Boehm_b} Boehm, B. W, Victor R. B, \textit{Software Defect Reduction Top 10 List}, Computer, v.34, 2001.



\end{thebibliography} 


\end{document}

